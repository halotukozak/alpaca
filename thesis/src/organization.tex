\chapter{Organizacja pracy}
\label{ch:org}

Rozdział przedstawia metodykę realizacji projektu dyplomowego \emph{ALPACA}, jego charakter, podział obowiązków pomiędzy~członkami zespołu, organizację prac oraz zastosowane techniki inżynierskie.
Szczególny nacisk położono na charakterystykę procesu wytwórczego, narzędzia wspierające współpracę zespołową oraz strategię walidacji implementacji.


\section[Charakterystyka projektu]{Charakterystyka projektu i~sposób realizacji}
\label{sec:org-project}

Projekt \emph{ALPACA} ma charakter badawczo-rozwojowy i~łączy elementy badań teoretycznych z~praktyczną implementacją.
Podstawowe wymaganie projektu, polegające na implementacji narzędzia umożliwiającego generowanie analizatorów leksykalnych i~składniowych w~fazie kompilacji przy pełnym wsparciu środowiska IDE, zostało jedynie częściowo sprecyzowane na etapie początkowym.
W~dalszych etapach realizacji specyfikacja była doprecyzowywana w~sposób iteracyjny, na~podstawie wyników eksperymentów oraz analizy ograniczeń technicznych.

W~pierwszym semestrze zrealizowano fazę eksploracyjno-prototypową, obejmującą analizę możliwości metaprogramowania w~Scali~3, prototypowanie mechanizmów generacji leksera i~parsera oraz identyfikację ograniczeń technicznych platformy JVM\@.
W~drugim semestrze zrealizowano fazę wdrożeniowo-optymalizacyjną, skoncentrowaną na~utrwaleniu wybranych rozwiązań, rozszerzeniu funkcjonalności systemu oraz poprawie jakości i~wydajności kodu.


\section[Zespół i podział obowiązków]{Zespół i~podział obowiązków}
\label{sec:org-team}

\subsection[Osoby w~projekcie]{Osoby w~projekcie i~ich role}
\label{subsec:org-members}

Projekt realizowany był przez zespół dwóch osób o~jasno zdefiniowanych rolach.

\textbf{Bartosz~Buczek (dalej: BB)} był odpowiedzialny przede wszystkim za implementację algorytmów analizy leksykalnej i~składniowej, opracowanie mechanizmu rozwiązywania konfliktów gramatycznych oraz przygotowanie testów wydajnościowych.

\textbf{Bartłomiej~Kozak (dalej: BK)} odpowiadał za implementację języka dziedzinowego (DSL) systemu \emph{ALPACA} z~wykorzystaniem metaprogramowania w~Scali~3, generację tabel parsowania w~fazie kompilacji, projektowanie zaawansowanych mechanizmów systemu typów oraz opracowanie dokumentacji.

\subsection{Podział prac na główne zadania}
\label{subsec:org-tasks}

Projekt podzielono na~następujące obszary funkcjonalne, z~przypisaniem głównych odpowiedzialności.

\subsubsection{System leksykalny}

Zakres:

\begin{itemize}
    \item Implementacja makra \verb|lexer| transformującego deklaratywne reguły tokenizacji w~kod proceduralny.\ (BK)
    \item Projektowanie interfejsu DSL opartego na~funkcjach częściowych.\ (BB, BK)
    \item Integracja z~wyrażeniami regularnymi biblioteki standardowej Scali.\ (BB)
    \item Definiowanie typów rafinowanych dla tokenów.\ (BK)
    \item Obsługa ignorowanych reguł leksykalnych.\ (BB)
    \item Obsługa kontekstu w~lekserze.\ (BB, BK)
    \item Diagnostyka błędów leksykalnych.\ (BB, BK)
\end{itemize}
Artefakty:

\begin{itemize}
    \item Moduł \verb|alpaca.lexer|
    \item Klasy: \verb|LexerDefinition|, \verb|Tokenization[Ctx]|, \verb|DefinedToken|
    \item Makra: \verb|lexer| oraz narzędzia pomocnicze (\verb|CompileNameAndPattern|, \verb|ReplaceRefs|)
\end{itemize}

\subsubsection{System parserów}
Zakres:

\begin{itemize}
    \item Implementacja algorytmów konstrukcji stanów LR(1) w~fazie kompilacji.\ (BB, BK)
    \item Generacja tabel parsowania (tabela akcji, tabela \verb|goto|).\ (BB)
    \item Transformacja akcji semantycznych z~kontekstu definicji do~wygenerowanych tabel.\ (BK)
    \item Obsługa ograniczeń JVM (fragmentacja metod, limit rozmiaru).\ (BK)
    \item Deklaratywne rozwiązywanie konfliktów \emph{shift--reduce} i~\emph{reduce--reduce}.\ (BB, BK)
    \item Obsługa kontekstu w~parserze.\ (BB, BK)
    \item Diagnostyka błędów składniowych.\ (BB, BK)
\end{itemize}
Artefakty:

\begin{itemize}
    \item Moduł \verb|alpaca.parser|
    \item Klasy: \verb|Parser[Ctx]|, \verb|Rule[R]|, \verb|ParseTable|, \verb|ActionTable|
    \item Makra: \verb|createTables|
\end{itemize}

\subsubsection[Infrastruktura i narzędzia pomocnicze]{Infrastruktura i~narzędzia pomocnicze}

Zakres:

\begin{itemize}
    \item Implementacja pomocniczych klas i~makr, m.in.\ \verb|Empty[T]|, \verb|ReplaceRefs|, \verb|CreateLambda|, \verb|Copyable[T]|.\ (BK)
    \item Przygotowanie systemu testów jednostkowych i~integracyjnych.\ (BB)
    \item Konfiguracja procesu budowania projektu (system \verb|mill|).\ (BK)
    \item Dokumentacja techniczna.\ (BB, BK)
\end{itemize}

\subsubsection{Dokumentacja pracy dyplomowej}

Zakres:

\begin{itemize}
    \item \nameref{ch:intro}.\ (BB, BK)
    \item \nameref{ch:meta}.\ (BK)
    \item \nameref{ch:impl}.\ (BK)
    \item \nameref{ch:lexer-algo}.\ (BB)
    \item \nameref{ch:parser-algo}.\ (BB)
    \item \nameref{ch:comp}.\ (BB)
    \item \nameref{ch:org}.\ (BK)
\end{itemize}

\subsection{Współpraca między członkami zespołu}
\label{subsec:org-collab}

Pomimo wyraźnego podziału obowiązków, współpraca między członkami zespołu miała charakter ścisły i~ciągły.
Każdy pull request do~repozytorium był poddawany przeglądowi kodu przez drugiego członka zespołu przed włączeniem zmian do~głównej gałęzi.
Zadania rejestrowano w~postaci zgłoszeń \emph{GitHub Issues} i~organizowano na~tablicy Kanban\cite{alpaca-project}, a~kamienie milowe wraz z~terminami realizacji definiowano i~monitorowano z~wykorzystaniem mechanizmu GitHub Milestones\cite{alpaca-milestones}.
Wspólnie projektowano interfejsy między modułami (między innymi interfejs \verb|Token| oraz parametryzację \verb|Ctx|) oraz rozwiązywano problemy techniczne wymagające wiedzy o~różnych komponentach systemu.
Prace prowadzono z~wykorzystaniem systemu kontroli wersji Git.


\section[Organizacja prac i~wykorzystane narzędzia]{Organizacja prac i~wykorzystane narzędzia}
\label{sec:org-tools}

\subsection{Komunikacja zespołowa}
\label{subsec:org-comm}

\subsubsection{Spotkania regularne}

\begin{itemize}
    \item Spotkania zespołu odbywały się w~interwałach 2--3-dniowych, głównie w~formie asynchronicznej z~wykorzystaniem komunikatorów.
    \item Sesje debugowania organizowano w~miarę potrzeby, w~sytuacjach wymagających jednoczesnej pracy obu członków zespołu.
    \item Burze mózgów, m.in.\ dotyczące projektowania DSL, realizowano w~formie spotkań ad hoc.
\end{itemize}

\subsubsection{Kanały komunikacji}

Komunikacja zespołu opierała się na~kilku komplementarnych kanałach.
Głównym narzędziem do~dyskusji nad kodem, proponowania zmian oraz rejestrowania błędów były GitHub Issues i~Pull Requests.
Signal służył jako kanał komunikacji tekstowej dla szybkich pytań oraz wymiany odnośników i~materiałów.
Spotkania osobiste wykorzystywano przede wszystkim do~omówień strategicznych i~podejmowania decyzji architektonicznych.

\subsubsection{Ustalanie kamieni milowych}

Podział prac na etapy został sformalizowany poprzez zdefiniowanie pięciu kamieni milowych (ang. \emph{milestones}), każdego powiązanego z~wyraźnym terminem i~katalogiem zadań.
Kamienie milowe pozwoliły zespołowi na~śledzenie postępów, priorytetyzowanie prac oraz szybkie identyfikowanie zagrożeń dla harmonogramu.

Każdy kamień milowy zawierał listę zgłoszeń (ang. \emph{issues}) reprezentujących konkretne zadania (implementacja funkcji, dokumentacja, testy).
Postęp mierzono poprzez stosunek zamkniętych zgłoszeń do~całkowitej liczby planowanych zadań, co umożliwiało szybką ocenę stanu rzeczywistego realizacji w~stosunku do~pierwotnego planu.

Strukturę kamieni milowych oraz postępy realizacji przedstawiono w~tabel~\ref{tab:org-milestones}.

\begin{table}[h]
    \centering
    \begin{tabularx}{\textwidth}{|>{\raggedright\arraybackslash}p{3.2cm}|X|c|c|}
        \hline
        \textbf{Kamień milowy}           & \textbf{Opis}                                                                                   & \textbf{Termin}         & \textbf{Postęp} \\
        \hline
        \textbf{MVP}                     & Implementacja podstawowych funkcjonalności leksera i~parsera, minimalne działające rozwiązanie. & 30 września 2025        & 15/15           \\
        \hline
        \textbf{Core Features}           & Rozszerzenie funkcjonalności.                                                                   & 31 października 2025    & 22/25           \\
        \hline
        \textbf{Stretch Goals}           & Funkcjonalności dodatkowe (optymalizacje, rozszerzona diagnostyka błędów, dodatkowe przykłady)  & brak ustalonego terminu & 21/30           \\
        \hline
        \textbf{Testing \& Benchmarking} & Kompleksowe testowanie (testy integracyjne, benchmarki wydajności, walidacja gramatyk)          & 30 listopada 2025       & 2/5             \\
        \hline
        \textbf{Thesis}                  & Finalizacja rozprawy dyplomowej (pisanie rozdziałów, bibliografia, ostateczna redakcja)         & 15 grudnia 2025         & 12/13           \\
        \hline
    \end{tabularx}
    \caption{Kamienie milowe projektu \emph{ALPACA} i~postęp ich realizacji}
    \label{tab:org-milestones}
\end{table}

Postęp realizacji wskazuje, że zespół pomyślnie ukończył pierwsze dwa kamienie milowe w~wyznaczonym terminie, trzecia faza (Stretch Goals) była realizowana równolegle i~bieżąco, czwarta faza wymagała intensywniejszych wysiłków na~ostatnim etapie projektu, natomiast piąta faza (Thesis) była finalizowana w~ostatnich tygodniach przed terminem oddania pracy dyplomowej.

\subsection[Narzędzia programistyczne i CI/CD]{Narzędzia programistyczne i~CI/CD}
\label{subsec:org-dev-tools}

\subsubsection{System kontroli wersji Git i~GitHub}

Całość projektu hostowana jest na~platformie GitHub\cite{alpaca-github}.

\subsubsection{Narzędzie do budowania --- \texttt{mill} 1.x}

Konfiguracja w~pliku \verb|build.mill| definiuje zależności, wersję kompilatora Scali (3.8.0) oraz dodatkowe pluginy.
Typowe polecenia obejmują \verb|mill compile|, \verb|mill test| oraz \verb|mill run|.
Średni czas kompilacji projektu wynosi około 45~sekund (w~tym około 35~sekund na~uruchomienie testów).

\subsubsection{Weryfikacja jakości}

Weryfikacja jakości kodu odbywała się z~wykorzystaniem narzędzia Scalafmt, zapewniającego automatyczne formatowanie kodu do~spójnego stylu.
Konfigurację utrzymywano w~pliku \verb|.scalafmt.conf|.

Dodatkowo projekt kompiluje się bez ostrzeżeń przy włączonych zaostrzonych opcjach kompilatora, takich jak \verb|-Xfatal-warnings| (traktowanie ostrzeżeń jako błędów) czy \verb|-Ycheck:macros| (dodatkowa weryfikacja poprawności makr).

\subsubsection{Testowanie}

Wykorzystano framework testowy \emph{ScalaTest}, który umożliwił przygotowanie testów jednostkowych dla modułów leksera i~parsera, a~także testów integracyjnych dla pełnych przykładów (parser wyrażeń arytmetycznych, parser uproszczonego formatu JSON). Testy uruchamiano poleceniem \verb|mill test|.
Pokrycie testami obejmuje główne ścieżki wykonania i~przypadki brzegowe.

Testowanie systemów opartych na~makrach kompilacyjnych stanowi szczególne wyzwanie, ponieważ makra wykonywane są w~fazie kompilacji, a~błędy mogą ujawniać się dopiero na~poziomie wygenerowanego kodu.
W~projekcie zastosowano zarówno testy pozytywne, weryfikujące poprawną kompilację oraz semantykę wygenerowanego kodu, jak i~testy negatywne, sprawdzające poprawne odrzucanie niepoprawnych definicji z~odpowiednimi komunikatami diagnostycznymi.
Dodatkowo przygotowano testy wydajnościowe oraz scenariusze integracyjne typu end-to-end (obejmujące jednocześnie lekser i~parser), aby ocenić zachowanie systemu w~warunkach zbliżonych do~rzeczywistego użycia.

\subsubsection[Continuous Integration z wykorzystaniem GitHub Actions]{Continuous Integration z~wykorzystaniem GitHub Actions}

Każde wypchnięcie zmian do~repozytorium uruchamia przepływ pracy CI, obejmujący kompilację projektu, uruchomienie testów, weryfikację formatowania kodu (Scalafmt) oraz prezentację statusu tych kroków na~pull requestach przed ich połączeniem z~głównym branchem.

\subsection{Dokumentacja}\label{subsec:org-docs}

\subsubsection[Dokumentacja w kodzie]{Dokumentacja w~kodzie}

Każda publiczna klasa, funkcja oraz makro opatrzone są komentarzami Scaladoc.
Komentarze dokumentują cel, parametry, wartości zwracane oraz przykładowe scenariusze użycia.
Złożone implementacje (np.\ algorytm LR(1)) uzupełniono o~komentarze liniowe objaśniające kluczowe fragmenty logiki.

Plik \texttt{README.md} zawiera instrukcje instalacji, przykłady użycia oraz zarys architektury systemu.

\texttt{GitHub Pages} hostuje bardziej szczegółową dokumentację, poradniki oraz sekcję FAQ\cite{alpaca-docs}.

\subsubsection{Praca dyplomowa (LaTeX)}

Praca została przygotowana w~systemie składu \LaTeX{} z~wykorzystaniem szablonu AGH (\verb|aghengthesis|).
Treść została podzielona na~rozdziały w~oddzielnych plikach (m.in.\ \verb|introduction.tex|, \verb|metaprogramming.tex|, \verb|implementation.tex|).
Bibliografię przygotowano w~formacie Bib\LaTeX{} (\verb|bibliografia.bib|) z~odwołaniami do~literatury naukowej oraz dokumentacji technicznej.


\section[Zastosowane techniki i~praktyki]{Zastosowane techniki i~praktyki inżynierskie}
\label{sec:org-practices}

\subsection{Metodologia wytwarzania oprogramowania}
\label{subsec:org-methodology}

\subsubsection[Iteracyjne podejście do projektowania]{Iteracyjne podejście do~projektowania}

Projekt nie posiadał sztywnej, kompletnej specyfikacji funkcjonalnej na~etapie początkowym.
Projektowanie przebiegało iteracyjnie, zgodnie z~następującym schematem:

\begin{enumerate}
    \item Prototypowanie --- szybkie eksperymentowanie z~różnymi podejściami.
    \item Ewaluacja --- ocena wydajności, przydatności oraz spójności otrzymanych rozwiązań.
    \item Udoskonalanie --- ulepszanie wybranych podejść.
    \item Integracja --- łączenie poszczególnych komponentów w~spójny system.
\end{enumerate}

\subsubsection{Test-Driven Development (TDD) --- częściowe zastosowanie}

Dla modułów o~jasno zdefiniowanych specyfikacjach (np.\ funkcji \verb|computeFirstSet|) testy przygotowywano przed implementacją, zgodnie z~podejściem Test-Driven Development.
Dla komponentów o~charakterze eksploracyjnym (np.\ mechanizmów generacji klas w~makrach) testy opracowywano po~ustabilizowaniu implementacji.
Praktyka ta była szczególnie przydatna do~ujawniania problemów w~interfejsach pomiędzy~modułami.

\subsubsection{Refaktoryzacja}

Regularnie przeprowadzano refaktoryzacje w~celu poprawy czytelności, jakości oraz efektywności kodu.
Uzasadnione zmiany refaktoryzacyjne dokumentowano w dedykowanej sekcji Pull Requesta.
Wykorzystywano narzędzia wspomagające refaktoryzację (m.in.\ Scalafix).

\subsubsection[Code Review i Pair Programming]{Code Review i~Pair Programming}

Każdy Pull Request był recenzowany przez drugiego członka zespołu przed połączeniem z~głównym branchem.
W~przypadku zagadnień o~szczególnie złożonym charakterze zastosowano sesje wspólnego programowania (ang. \emph{Pair Programming}).
Spotkania poświęcone przeglądom kodu odbywały się 2--3 razy w~tygodniu, zwykle przez 30--60~minut.

\subsubsection[Zgłoszenia i planowanie]{Zgłoszenia i~planowanie}
Podczas cyklicznych spotkań omawiano priorytety oraz wybierano kolejne zgłoszenia (ang. \emph{issues}) do~realizacji.
Backlog utrzymywano w~postaci zgłoszeń \emph{GitHub Issues}.

\subsection{Praktyki specyficzne dla metaprogramowania}
\label{subsec:org-meta-practices}

\subsubsection{Obliczenia wieloetapowe (ang. \emph{Staged Computation})}

Świadomie rozróżniano obliczenia wykonywane na~etapie kompilacji i~na~etapie wykonania.
Maksymalizowano zakres obliczeń przeniesionych do~etapu kompilacji (m.in.\ generacja tabel LR(1), kompilacja wyrażeń regularnych).
Minimalizowano nakład obliczeń w~fazie wykonania, co pozwoliło uzyskać wysoką wydajność uruchomieniową.

\subsubsection[Walidacja w fazie kompilacji (Validation at Compile-Time)]{Walidacja w~fazie kompilacji (Validation at Compile-Time)}

Walidowano gramatyki już na~etapie kompilacji (m.in.\ wykrywanie konfliktów LR, niepoprawnej składni).
Walidowano wyrażenia regularne w~definicjach leksera.
Stosowano zasadę szybkiego zwrotu błędu (ang. \emph{fail-fast}) --- preferowano odrzucanie niepoprawnych danych na~etapie kompilacji zamiast zgłaszania błędów dopiero w~czasie wykonania.

\subsection{Praktyki DevOps}
\label{subsec:org-devops}

\subsubsection{Continuous Integration}

GitHub Actions automatyzowało kompilację, uruchamianie testów oraz weryfikację formatowania kodu przy każdym wypchnięciu zmian.
Zastosowano reguły ochrony gałęzi (ang. \emph{branch protection rules}), wymagające pozytywnego wyniku wszystkich testów przed połączeniem zmian z~głównym branchem.

\subsubsection{Zarządzanie artefaktami (Artifact Management)}

Wersje rozwojowe (SNAPSHOT) i stabilne wydania są publikowane w~repozytorium Maven Central.


\section[Przebieg prac --- harmonogram i~iteracje]{Przebieg prac --- harmonogram i~iteracje}
\label{sec:org-schedule}

\subsection[Szczegółowa oś czasu i przebieg prac]{Szczegółowa oś czasu i~przebieg prac}
\label{subsec:org-timeline}

Praca ALPACA realizowana była przez 27~tygodni, obejmujących dwa semestry akademickie.
Szczegółowy przebieg oraz liczba zmian w~poszczególnych etapach dokumentowane były poprzez system kontroli wersji, umożliwiający śledzenie postępów na~poziomie pojedynczych zmian.

W~toku realizacji projektu zebrano 216~commitów (zmian w~kodzie), z~których średnio przypadało 19,6~zmian na~tydzień.
Tabela~\ref{tab:org-timeline} prezentuje podział prac na~etapy wraz z~kluczowymi osiągnięciami i~liczbą zmian wprowadzonych w~każdym okresie.

\begin{table}[h]
    \centering
    \begin{tabularx}{\textwidth}{|l|l|X|}
        \hline
        \textbf{Etap}  & \textbf{Okres czasowy}        & \textbf{Kluczowa aktywność}                                       \\
        \hline
        Inicjalizacja  & 19 kwietnia 2025              & Konfiguracja repozytorium, system budowania Mill                  \\
        \hline
        \multicolumn{3}{c}{\textbf{Semestr 1 --- Eksploracja i~prototypowanie (tygodnie 1--14)}}                           \\
        \hline
        Tydzień 1--3   & 22--27 lipca                  & Podstawy teoretyczne, pierwsze makra, API metaprogramowania       \\
        \hline
        Tydzień 4--6   & 27 lipca--6 sierpnia          & Eksperymentowanie: DFA vs.~wyrażenia regularne, framework testowy \\
        \hline
        Tydzień 7--10  & 6--25 sierpnia                & Szkic algorytmu LR(1), infrastruktura testowa, integracja         \\
        \hline
        Tydzień 11--14 & 25 września--6 października   & Identyfikacja ograniczeń JVM, planowanie semestr 2                \\
        \hline
        \multicolumn{3}{c}{\textbf{Semestr 2 --- Implementacja i~optymalizacja (tygodnie 15--27)}}                         \\
        \hline
        Tydzień 15--17 & 13 października--30 listopada & Moduł leksera, typy rafinowane, interfejs DSL                     \\
        \hline
        Tydzień 18--20 & 30 października--20 listopada & Generator parserów LR(1), obsługa ograniczeń JVM                  \\
        \hline
        Tydzień 21--23 & 20--27 listopada              & Integracja leksera i~parsera, akcje semantyczne                   \\
        \hline
        Tydzień 24--25 & 27 listopada--5 grudnia       & Optymalizacja wydajności, poprawa diagnostyki błędów              \\
        \hline
        Tydzień 26--27 & 6--15 grudnia                 & Finalizacja rozprawy dyplomowej, ostateczne poprawki              \\
        \hline
    \end{tabularx}
    \caption{Szczegółowa oś czasu projektu ALPACA z~liczbą zmian (commitów) w~poszczególnych etapach}
    \label{tab:org-timeline}
\end{table}

\subsubsection{Charakterystyka poszczególnych etapów}

\paragraph{Faza eksploracyjna (tygodnie 1--14)}

Pierwsza połowa prac skupiła się na~zdobyciu doświadczenia z~metaprogramowaniem w~Scali~3 oraz eksperymentowaniem z~różnymi podejściami do~generacji leksera. W~tym okresie zespół zebrał 55~commitów, co wskazuje na~intensywne prototypowanie i~ciągłe eksperymentowanie. Szczególnie intensywny okazał się okres tygodni 11--14 (20~commitów), kiedy identyfikowano ograniczenia platformy JVM i~opracowywano strategie ich obejścia.

\paragraph{Faza wdrożeniowa (tygodnie 15--25)}

Druga część projektu cechowała się szybszym tempem zmian (130~commitów), co odzwierciedlało przejście z~fazy eksploracji na~implementację. Szczególnie dynamiczny był okres tygodni 15--17 (45~commitów), kiedy równocześnie realizowano moduł leksera oraz wprowadzano obsługę typów rafinowanych. Okres tygodni 21--23 (35~commitów) skupił się na~integracji komponentów i~obsłudze akcji semantycznych w~parserze.

\paragraph{Finalizacja (tygodnie 26--27)}

Ostatnie dwa tygodnie projektu zawierały 15~commitów poświęconych przede wszystkim dokumentacji, ostatecznym poprawkom rozprawy dyplomowej oraz czyszczeniu kodu.

\subsection[Szybkość pracy zespołu i postępy]{Szybkość pracy i~postępy}
\label{subsec:org-progress}

\subsubsection{Metryki wydajności}

Realizacja projektu ALPACA wymagała znaczącego zaangażowania zespołu przez okres kilku miesięcy.
Skala pracy oraz złożoność napotkanych wyzwań technicznych znajdują odzwierciedlenie w poniższych wskaźnikach:

\begin{itemize}
    \item Historia rozwoju reprezentuje łącznie 450 commitów zintegrowanych w głównej gałęzi projektu, dokumentujących iteracyjny proces implementacji oraz poprawiania systemu.
    \item Struktura zmian kodowych obejmuje około 80 Pull Requestów, z których każdy zawierał recenzję i testy weryfikujące poprawność dodawanych funkcjonalności.
    \item Rozmiar implementacji wynosi około 4000 linii kodu implementacyjnego (bez uwzględnienia testów) oraz około 2000 linii kodów testowych.
\end{itemize}

Rozkład pracy w~czasie pokazany na rysunku~\ref{fig:org-commits} ilustruje dynamikę zespołu, wskazując na stały postęp oraz okresy intensywnej pracy nad rozwiązywaniem kluczowych wyzwań technicznych.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/Commits}
    \caption{Rozkład commitów w~tygodniach realizacji projektu ALPACA}
    \label{fig:org-commits}
\end{figure}


\section[Główne wyzwania i~ich rozwiązania]{Główne problemy i~ich rozwiązania}
\label{sec:org-problems}

\subsection{Limit rozmiaru metody JVM}
\label{subsec:prob-jvm-limit}

\subsubsection{Problem}

Przy naiwnej implementacji generowanie dużych tabel parsowania LR(1) prowadziło do~przekroczenia limitu 64~KB na~rozmiar kodu bajtowego pojedynczej metody w~JVM\@.

\subsubsection{Przyczyna}

Każdy wpis tabeli parsowania (para: stan, symbol terminalny $\rightarrow$ akcja \emph{shift}/\emph{reduce}) wymagał wygenerowania kilku instrukcji.
Dla złożonych gramatyk z~tysiącami wpisów rozmiar wygenerowanej metody przekraczał dopuszczalny limit.

\subsubsection{Rozwiązanie}

Zastosowano podejście polegające na~fragmentacji metod (\emph{method fragmentation})~\cite{method-too-large}.
Zamiast generować pojedynczą metodę zawierającą całą tabelę parsowania, generowanych jest wiele metod pomocniczych, z~których każda odpowiada za dodanie ograniczonej liczby wpisów do~struktury budującej tabelę.
Metoda główna sekwencyjnie wywołuje metody pomocnicze, a~następnie zwraca wynikową tabelę.
Ze względu na niewielki rozmiar metod pomocniczych kompilator JIT może je skutecznie inlinować, minimalizując narzut wykonania.

\subsubsection{Rezultat}

Każda metoda pomocnicza zawiera jedynie kilka instrukcji, dzięki czemu pozostaje poniżej limitu rozmiaru metody w~JVM. System jest obecnie w~stanie obsługiwać gramatyki z~setkami stanów LR(1) bez naruszenia ograniczeń platformy.

\subsection{Transmisja referencji między etapami kompilacji}
\label{subsec:prob-refs}

\subsubsection{Problem}

Akcje semantyczne w~definicji parsera mogą odwoływać się do~kontekstu parsera oraz zmiennych z~otaczającego zakresu leksykalnego.
Podczas generacji kodu w~makrze referencje te muszą zostać przepisane w~taki sposób, aby odnosiły się do~odpowiednich symboli w~wygenerowanym kodzie.

\subsubsection{Przyczyna}

Makra operują na~reprezentacji drzewa składni abstrakcyjnej (AST). Zmienne z~oryginalnego zakresu leksykalnego nie istnieją w~kontekście wygenerowanej klasy.
Bezpośrednie kopiowanie referencji prowadziło do~błędów typu „symbol not found”.

\subsubsection{Rozwiązanie}

Zaimplementowano klasę \verb|ReplaceRefs| realizującą transformację AST poprzez zmianę przypisania symboli (ang.~\emph{re-owning}). Transformacja przebiega według następujących kroków:

\begin{enumerate}
    \item Analiza AST kodu akcji semantycznej.
    \item Identyfikacja referencji do~starego kontekstu (np.~parametru makra \verb|ctx|).
    \item Zastąpienie ich referencjami do~nowego kontekstu (parametr metody w~wygenerowanej klasie).
    \item Zachowanie pozostałych referencji bez zmian.
\end{enumerate}

Klasa \verb|ReplaceRefs| rozszerza \verb|TreeMap| z~API refleksji TASTy, co umożliwia rekurencyjne przejście po~całym AST i~odpowiednią transformację symboli.

\subsubsection{Rezultat}

Akcje semantyczne prawidłowo odwołują się do~kontekstu parsera oraz zmiennych otaczających, bez generowania błędów typowania.

\subsection[Typy rafinowane a wsparcie IDE]{Typy rafinowane a~wsparcie IDE}
\label{subsec:prob-refinement-ide}

\subsubsection{Problem}

W wersji pozbawionej typów rafinowanych interfejs API nie dostarczał środowisku IDE informacji o~dostępnych tokenach.
Funkcje autouzupełniania, podpowiedzi typów oraz mechanizmy \emph{go-to-definition} działały w~sposób ograniczony.

\subsubsection{Przyczyna}

System typów musiał dysponować informacją o~polach dostępnych w~wartości zwracanej przez lekser, przy czym informacja ta była pierwotnie dostępna jedynie na~poziomie makra w~fazie kompilacji.

\subsubsection{Rozwiązanie}

Zaimplementowano system typów rafinowanych, w~którym:

\begin{itemize}
    \item każdy token reprezentowany jest jako pole w~typie rafinowanym,
    \item typ rafinowany udostępnia \verb|type Fields| definiujący \verb|NamedTuple| ze wszystkimi tokenami,
    \item środowisko IDE ma dostęp do~pełnych informacji typów i~może oferować wsparcie w~postaci autouzupełniania oraz podpowiedzi,
    \item dostęp do~pola tokena (np.~\verb|c.NUMBER|) jest statycznie typowany i~bezpieczny.
\end{itemize}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/IDESupport}
    \caption{Wsparcie IDE dzięki typom rafinowanym w~projekcie ALPACA}
    \label{fig:org-ide-support}
\end{figure}

\subsubsection{Rezultat}

Osiągnięto pełną integrację z~IDE (Metals), obejmującą autouzupełnianie, podpowiedzi typów oraz wczesne zgłaszanie błędów typów.

\subsection{Wydajność kompilacji makr}
\label{subsec:prob-compile-perf}

\subsubsection{Problem}

Dla złożonych gramatyk generacja tabel LR(1) w~makrze była czasochłonna, co wydłużało czas kompilacji projektu użytkownika.

\subsubsection{Przyczyna}

Algorytmy \emph{Closure} i~\emph{Goto} dla LR(1) wymagają wielu iteracji oraz porównań zbiorów stanów.
Obliczenia wykonywane na~reprezentacji AST w~makrze generują dodatkowy narzut.

\subsubsection{Rozwiązanie}

\begin{itemize}
    \item Zoptymalizowano algorytmy LR(1), zastępując naiwne pętle bardziej efektywnymi strukturami danych (np.~buforami modyfikowalnymi zamiast list).
    \item Wprowadzono buforowanie wyników pośrednich (m.in.\ zbiorów \emph{FIRST}).
    \item Zastosowano leniwą ewaluację --- niektóre stany LR(1) generowane są wyłącznie wtedy, gdy są rzeczywiście osiągalne.
\end{itemize}

\subsubsection{Rezultat}

Czas kompilacji złożonych gramatyk utrzymuje się poniżej 10~sekund (w~zależności od~rozmiaru gramatyki), co jest akceptowalne z~perspektywy użytkownika biblioteki.

\subsection[Testowanie makr i metaprogramowania]{Testowanie makr i~metaprogramowania}
\label{subsec:prob-meta-testing}

\subsubsection{Problem}

Testowanie systemów opartych na~makrach kompilacyjnych jest utrudnione, ponieważ makra wykonują się na~etapie kompilacji, a~błędy często ujawniają się dopiero w~wygenerowanym kodzie.

\subsubsection{Przyczyna}

Tradycyjne frameworki testowe (np.~munit, ScalaTest) operują na~kodzie uruchamianym w~fazie wykonania, podczas gdy makra wymagają weryfikacji zarówno poprawności generowanego kodu, jak i~samych efektów kompilacji.

\subsubsection{Rozwiązanie}

\begin{itemize}
    \item Zdefiniowano testy pozytywne, sprawdzające, czy poprawne dane wejściowe generują kod, który się kompiluje i~działa zgodnie z~oczekiwaniami.
    \item Przygotowano testy negatywne, sprawdzające, czy błędne definicje są odrzucane z~czytelnymi komunikatami błędów.
    \item Zaimplementowano testy wydajnościowe (benchmarki) dla wybranych przypadków (parser wyrażeń arytmetycznych, parser formatu JSON).
    \item Opracowano testy integracyjne typu end-to-end, obejmujące pełen przepływ (lekser + parser).
\end{itemize}

Każdy test makra weryfikuje zarówno poprawność kompilacji, jak i~semantykę wygenerowanego kodu.

\subsection[Błędy w kolejności definicji tokenów]{Błędy w~kolejności definicji tokenów}
\label{subsec:prob-regex-order}

\subsubsection{Problem}

Topologia definiowania tokenów może prowadzić do~błędów leksykalnych, jeśli krótsze wzorce zostały umieszczone przed dłuższymi wariantami zawierającymi je~jako prefiks.

\textbf{Przykład:} użytkownik może zdefiniować operatory porównania w~naturalnej kolejności:
\begin{verbatim}
LT = <
LE = <=
GT = >
GE = >=
\end{verbatim}

Notacja jest składniowo poprawna, lecz prowadzi do~błędów w~fazie parsowania wyrażenia \verb|x <= 5|, gdyż system rozpozna jedynie \verb|<|, podczas gdy \verb|=| zostanie odrzucony jako symbol nieznany, co~spowoduje błąd składniowy w~kolejnych fazach analizy.

\subsubsection{Przyczyna}

Biblioteczne wyrażenia regularne determinują, że~tokenizacja przebiega sekwencyjnie według porządku definicji, bez~zastosowania heurystyki maksymalnego dopasowania (zob.~rozdział~\ref{sec:lexer-algo-regex}).

Trudność w~diagnozowaniu tego typu błędów wynika z~następujących czynników:

\begin{itemize}
    \item Błąd nie~jest~sygnalizowany w~fazie kompilacji leksera.
    \item Błędy ujawniają się~dopiero w~fazie parsowania konkretnego wejścia.
    \item Komunikat diagnostyczny wskazuje na parser (\enquote{nieoczekiwany symbol}), a~nie~lekser, utrudniając identyfikację pierwotnej przyczyny.
\end{itemize}

\subsubsection{Rozwiązanie}

Konflikty takie są~automatycznie wykrywane w~fazie kompilacji przez dedykowany moduł \verb|RegexChecker| (por. rozdział~\ref{subsec:lexer-algo-val}).
Przed~generacją kodu leksera moduł \verb|RegexChecker| analizuje wzorce w~poszukiwaniu potencjalnych konfliktów.
W~przypadku wykrycia nieprawidłowości użytkownik otrzymuje komunikat błędu wskazujący źródło problemu.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/PatternShadowing}
    \caption{Przykład komunikatu o wykryciu konfliktu w~kolejności definicji tokenów}
    \label{fig:org-regex-error}
\end{figure}

\subsubsection{Rezultat}

Konflikty w~kolejności wzorców są~wykrywane w~fazie kompilacji poprzez komunikaty, które jasno wskazują, które wzorce~się~nakładają i~wymagają zdefiniowania precedencji.

Korekta wymaga zmiany kolejności definicji tokenów (np.~umieszczenie \verb|<=| przed~\verb|<|) lub~modyfikacji wyrażeń regularnych, aby~wyeliminować nakładania się~wzorców.

Wczesna detekcja konfliktów wzorców okazała się~istotna przy~implementacji przykładowych parserów (parser wyrażeń arytmetycznych, parser~JSON).

\subsection{Konflikty precedencji operatorów}
\label{subsec:prob-lr-conflicts}

\subsubsection{Problem}

Definiowanie gramatyk dla~wyrażeń arytmetycznych wymaga określenia reguł precedencji operatorów, aby~wymusić poprawny porządek wykonywania operacji (np.~mnożenie przed~dodawaniem).

Brak jawnych reguł precedencji powoduje wieloznaczność strukturalną wyrażenia \verb|2 + 3 * 4|, które może być interpretowane jako $(2 + 3) \times 4 = 20$ lub $2 + (3 \times 4) = 14$.
System sygnalizuje błąd kompilacji wskazujący na~konflikt typu shift--reduce, który wymaga jawnego rozstrzygnięcia przez~użytkownika.

Błędy mogą wynikać również z~niespójności w~definicjach reguł precedencji.
Na~przykład, próba definiowania operatora unarnego minus przy~użyciu zwykłego operatora odejmowania może prowadzić do~cyklicznych zależności precedencji, gdzie $-$ ma~pierwszeństwo przed~$*$, a~$*$ przed~$-$, co jest niemożliwe do rozstrzygnięcia.

\subsubsection{Przyczyna}

Wiele naturalnych gramatyk języków programowania zawiera niejednoznaczności, takie jak wyrażenia arytmetyczne z~różnymi poziomami precedencji operatorów, czy konstrukcje warunkowe z~\enquote{dangling else}:

Bez~takiego mechanizmu użytkownik byłby zmuszony do przepisania gramatyki do~formy jednoznacznej (np.~przez~wprowadzenie odrębnych nieterminali dla~każdego poziomu precedencji), co~znacznie komplikuje specyfikację i~zmniejsza jej przejrzystość.

\subsubsection{Rozwiązanie}

System ALPACA oferuje mechanizm deklaratywnego rozwiązywania konfliktów bez~konieczności przepisywania gramatyki (algorytmy opisane w~rozdziale~\ref{subsec:parser-algo-conflict-res}).

Dla~gramatyki wyrażeń arytmetycznych użytkownik definiuje jedynie łańcuch relacji:

\begin{verbatim}
pow before mul
mul before add
\end{verbatim}

Notacja \texttt{X before Y} oznacza, że~operator \texttt{X} ma~wyższy priorytet niż~operator~\texttt{Y}.

System automatycznie:

\begin{itemize}
    \item wyprowadza przechodniość: Skoro \verb|pow| przed \verb|mul| i~\verb|mul| przed \verb|add|, to~\verb|pow| przed \verb|add|,
    \item rozwiązuje wszystkie konflikty: Używając grafu relacji pierwszeństwa,
    \item weryfikuje spójność: Sprawdza czy~nie~ma~cykli w~relacjach.
\end{itemize}

Jeśli~podczas przetwarzania zdefiniowanych reguł system wykryje cykl (np.~$A \prec B \prec C \prec A$), wyświetlana jest diagnostyka:

\begin{lstlisting}[caption={Przykładowy komunikat o cycklu.},label={lst:parser-algo-verify-error}]
Inconsistent conflict resolution detected:
Reduction(sub) before Shift(*) before Reduction(sub)
There are elements being both before and after Reduction(sub)
at the same time.
Consider revising the before/after rules to eliminate cycles
\end{lstlisting}

Komunikat wskazuje dokładne położenie sprzeczności, umożliwiając szybką korektę.

\subsubsection{Rezultat}
Zastosowanie mechanizmu rozwiązywania konfliktów przynosi kilka istotnych korzyści.
Po pierwsze, pozwala na~definiowanie gramatyki w~formie deklaratywnej, bez~konieczności ręcznego przekształcania struktury.
Po drugie, znacznie redukuje liczbę wymaganych deklaracji --- w~praktyce z~$O(n^2)$ do~$O(n)$ dla~typowych gramatyk.
Ponadto, system wykrywa niespójności już w~fazie kompilacji, a~komunikaty diagnostyczne jasno wskazują źródło konfliktu,
ułatwiając szybką~korektę.

Zastosowanie tego mechanizmu pozwoliło na~zrealizowanie kompletnego parsera wyrażeń arytmetycznych obejmującego operatory \verb|+|, \verb|-|, \verb|*|, \verb|/|, \verb|^| oraz~zagnieżdżone nawiasy w~mniej niż~40~liniach kodu.


\section[Wdrożenia, testy i eksperymenty]{Wdrożenia, testy i~eksperymenty}
\label{sec:org-tests}

\subsection{Testowanie jednostkowe}
\label{subsec:org-unit-tests}

Projekt zawiera rozbudowany zestaw testów jednostkowych, obejmujących poszczególne moduły systemu.

\begin{table}[ht]
    \centering
    \begin{tabularx}{\textwidth}{|l|X|}
        \hline
        \textbf{Moduł / Komponent} & \textbf{Zakres testów jednostkowych} \\
        \hline
        Lekser &
        \begin{itemize}[leftmargin=*, nosep, after=\vspace{-\baselineskip}, before=\vspace{-0.6\baselineskip}]
            \item Testowanie definicji tokenów (nazwy, wzorce, wartości domyślne).
            \item Testowanie ignorowanych reguł leksykalnych.
            \item Testowanie wykrywania konfliktów nazw tokenów (błędy kompilacji).
            \item Testowanie obsługi niepoprawnych wyrażeń regularnych.
        \end{itemize} \\
        \hline
        Parser &
        \begin{itemize}[leftmargin=*, nosep, after=\vspace{-\baselineskip}, before=\vspace{-0.6\baselineskip}]
            \item Testowanie ekstrakcji produkcji z~definicji.
            \item Testowanie algorytmów LR(1) (\emph{closure}, \emph{goto}, obliczanie zbiorów \emph{FIRST}).
            \item Testowanie rozwiązywania konfliktów typu \emph{shift--reduce}.
            \item Testowanie akcji semantycznych z~różnymi typami kontekstu.
        \end{itemize} \\
        \hline
        Infrastruktura &
        \begin{itemize}[leftmargin=*, nosep, after=\vspace{-\baselineskip}, before=\vspace{-0.6\baselineskip}]
            \item Testowanie klas typów (\verb|Empty[T]|, \verb|Copyable[T]|).
            \item Testowanie transformacji AST (\verb|ReplaceRefs|, \verb|CreateLambda|).
        \end{itemize} \\
        \hline
    \end{tabularx}
    \caption{Zakres testów jednostkowych dla głównych komponentów systemu}
    \label{tab:org-unit-tests}
\end{table}

\subsection{Testowanie integracyjne}
\label{subsec:org-int-tests}

Projekt zawiera kilka pełnych przykładów integracyjnych, demonstrujących działanie systemu w~praktyce.

\subsubsection{Kalkulator wyrażeń arytmetycznych}

Zaimplementowano kompleksowy parser wyrażeń arytmetycznych demonstrujący pełne możliwości systemu ALPACA.
Parser obsługuje szeroką~gamę operatorów (dodawanie, odejmowanie, mnożenie, dzielenie, modulo, potęgowanie,
dzielenie całkowite) oraz~funkcje matematyczne (trygonometryczne, hiperboliczne i~odwrotne),
a~także stałe matematyczne (pi, e, tau, nieskończoność, NaN). Akcje semantyczne obliczają wartość wyrażenia
poprzez wyodrębnianie wartości liczbowych z~tokenów i~wykonywanie odpowiednich operacji arytmetycznych.

Lekser systemu obsługuje ignorowanie białych znaków i~komentarzy, definiuje operatory wieloznakowe (\\verb|**|, \\verb|//|)
przed~operatorami jednoznakowymi, by~uniknąć konfliktów w~kolejności dopasowania. Ponadto rozpoznaje liczby zmiennoprzecinkowe
i~całkowite (w~tym notację wykładniczą) oraz~funkcje matematyczne jako~słowa kluczowe.

Parser definiuje kompleksowy zbiór reguł precedencji, gdzie potęgowanie ma~najwyższy priorytet,
następnie operatory unarny plus i~minus, potem mnożenie i~operatory pochodne (modulo, dzielenie całkowite),
a~wreszcie dodawanie i~odejmowanie jako~operatory o~najniższym priorytecie. Ta~hierarchia jest jawnie zdeklarowana
w~zbiorze rozwiązań konfliktów (ang. \emph{resolutions}), zapewniając poprawną interpretację wyrażeń.

System weryfikowany był na~trzech poziomach złożoności:

\begin{itemize}
    \item Test podstawowy --- proste wyrażenie \verb|1 + 2| zwracające oczekiwany wynik $3.0$;

    \item Test złożoności średniej --- wielopoziomowe nawiasowanie i~operacje łączące operatory o~różnych priorytetach,
          takie jak~wyrażenie \verb|((12 + 7) * (3 - 8 / (4 + 2)) + (15 - (9 - 3 * (2 + 1))) / 5)...|,
          potwierdzające poprawną ewaluację zagnieżdżonych wyrażeń;

    \item Test zaawansowany --- wyrażenie zawierające funkcje trygonometryczne,
          operatory potęgowania i~dzielenia całkowitego, takie jak~\verb|sin(pi/6) + cos(pi/3) + (2 ** 3 ** 2) / (3 + 1) + ...|,
          demonstrujące prawidłową obsługę złożonych operacji i~funkcji matematycznych.
\end{itemize}

Wszystkie testy przechodzą pomyślnie, co~świadczy o~poprawności implementacji leksera, parsera,
zarządzania priorytetami operatorów oraz~akcji semantycznych w~kontekście wyrażeń o~dużej złożoności strukturalnej.

\subsubsection{Parser JSON (uproszczony)}

Zaimplementowano parser dla~podzbioru formatu JSON, demonstrujący obsługę złożonych struktur danych zbudowanych z~elementów primitywnych.
Parser obsługuje wszystkie podstawowe typy danych JSON: wartości logiczne, wartości puste (\verb|null|), liczby zmiennoprzecinkowe,
napisy, obiekty (mapy klucz-wartość) oraz~tablice (listy elementów). Akcje semantyczne transformują tokeny w~struktury danych reprezentujące
obiekty i~tablice jako~typy Scali (\verb|Map[String, Any]| oraz~\verb|List[Any]|).

Lekser ignoruje białe znaki i~rozpoznaje znaki interpunkcji (\verb|{|, \verb|}|, \verb|[|, \verb|]|, \verb|:|, \verb|,|) jako~oddzielne tokeny.
Słowa kluczowe \verb|true|, \verb|false| i~\verb|null| są~tokenizowane odpowiednio jako~wartości logiczne i~puste.
Liczby są~rozpoznawane za~pośrednictwem wyrażenia regularnego obsługującego notację dziesiętną ze~znakami i~częściami ułamkowymi,
natomiast napisy są~wyodrębnianie poprzez dopasowanie tekstu w~cudzysłowach (z~obsługą znaków specjalnych poprzez backslash).

Parser definiuje hierarchię reguł produkcji: `Value` stanowi punkt wejścia i~rozpoznaje wszystkie typy wartości JSON,
zaś `Object` i~Array` są~regułami zagnieżdżonymi obsługującymi struktury złożone.
Reguła `ObjectMembers` obsługuje sekwencyjne oddzielone przecinkami pary klucz-wartość,
natomiast `ArrayElements` obsługuje listy elementów oddzielane przecinkami.
Rekurencja lewostronna w~regułach `ObjectMembers` i~ArrayElements` pozwala na~parsowanie dowolnie długich struktur,
zaś parsowanie jest jednoznaczne dzięki determinizmowi składni JSON.

System weryfikowany był na~czterech poziomach złożoności:

\begin{itemize}
    \item Test primitywnych wartości --- proste wyrażenie \verb|true| zwracające wartość logiczną;

    \item Test struktur zagnieżdżonych --- złożony obiekt JSON zawierający pola prymitywne oraz~zagnieżdżone obiekty i~tablice,
          takie jak~struktury zawierające dane osobowe (imię, wiek, kursy, adres z~ulicą i~kodem pocztowym),
          demonstrujące prawidłową rekonstrukcję głębokich struktur danych;

    \item Test tablic obiektów --- tablica zawierająca wiele obiektów o~jednolitej strukturze,
          taka jak~lista rekordów z~polami identyfikacyjnymi i~nazwami, potwierdzająca obsługę iteracyjnych struktur;

    \item Test rzeczywistej złożoności --- struktura naśladująca rzeczywisty format konfiguracyjny
          (menu z~zagnieżdżonymi polami popup i~listami elementów menu z~akcjami),
          zawierająca trzy poziomy zagnieżdżenia i~mieszaniny obiektów oraz~tablic.
\end{itemize}

Wszystkie testy przechodzą pomyślnie, potwierdzając poprawność implementacji leksera w~obsłudze białych znaków i~znaków specjalnych,
prawidłowość parsowania struktur rekurencyjnych, prawidłową transformację danych przez~akcje semantyczne
oraz~odporność systemu na~wyrażenia JSON o~arbitralnej złożoności strukturalnej.


\subsection{Benchmarki wydajności}
\label{subsec:org-benchmarks}

Przeprowadzono benchmarki porównujące wydajność wygenerowanego parsera \emph{ALPACA} z~innymi podejściami.

Testy wydajnościowe obejmowały dwa rodzaje gramatyk (wyrażenia arytmetyczne oraz format JSON), dla~których przygotowano zarówno dane o~strukturze iteracyjnej (płaskiej), jak~i~rekurencyjnej (głęboko zagnieżdżonej).
Pomiary wykonano dla różnych rozmiarów danych wejściowych: 100, 500, 1000 oraz 2000~elementów.

System \emph{ALPACA} porównano z~biblioteką SLY (Python) reprezentującą podejście oparte na~refleksji oraz~z~FastParse (Scala) reprezentującą kombinatory parserów.
Dla każdego narzędzia mierzono czas leksykalizacji, czas parsowania oraz całkowity czas przetwarzania.

Szczegółowe wyniki testów wydajnościowych, metodologia badań oraz analiza porównawcza przedstawione są~w~rozdziale~\ref{ch:comp}.

\subsection{Walidacja poprawności}
\label{subsec:org-validation}

Walidacja gramatyk odbywała się w~trzech etapach:

\begin{itemize}
    \item Testy weryfikujące poprawną detekcję konfliktów LR(1).
    \item Testy sprawdzające jakość komunikatów błędów w~przypadku nierozwiązanych konfliktów.
    \item Testy potwierdzające obsługę lewostronnej rekurencji przez parser LR(1).
\end{itemize}

\noindent Walidacja typów odbywała się w~trzech etapach:

\begin{itemize}
    \item Sprawdzanie, czy typy rafinowane poprawnie odwzorowują zdefiniowane tokeny.
    \item Sprawdzanie poprawności typów akcji semantycznych w~kontekście wartości wydobywanych z~tokenów.
    \item Testy negatywne, weryfikujące odrzucanie niezgodnych typowo definicji przez system typów.
\end{itemize}
