\chapter{\chaptertitleprojectvision}
\label{ch:cel-wizja}


\section{Charakterystyka problemu}
\label{sec:charakterystyka-problemu}
Leksery i parsery są kluczowymi elementami w procesie tworzenia interpreterów i kompilatorów języków programowania.
Pozwalają one przekształcić kod źródłowy napisany przez programistę na reprezentację wewnętrzną, wykorzystywaną później przez dalsze etapy przetwarzania kodu.

Analiza leksykalna wykonywana przez lekser polega na rozdzieleniu kodu źródłowego na jednostki logiczne, zwane leksemami.
Parser natomiast wykonuje analizę składniową w celu ustalenia struktury gramatycznej tekstu i jej zgodności z gramatyką języka.

Celem pracy inżynierskiej jest stworzenie narzędzia \textit{ALPACA} (Another Lexer Parser And Compiler Alpaca) w języku Scala, które implementuje funkcjonalności powszechnie stosowane w budowie lekserów i parserów.


\section{Motywacja projektu}
\label{sec:motywacja-projektu}

Projekt ma na celu stworzenie nowoczesnego narzędzia do generowania lekserów i parserów w języku Scala, łączącego zalety istniejących rozwiązań z nowoczesnym podejściem technologicznym. Jego główne cele to:
\begin{enumerate}
    \item Stworzenie intuicyjnego API.
    \item Opracowanie obszernej dokumentacji.
    \item Rozbudowana diagnostyka błędów.
    \item Poprawa wydajności względem rozwiązań w języku Python.
    \item Integracja z popularnymi środowiskami programistycznymi (IDE).
\end{enumerate}

Proponowane rozwiązanie łączy nowoczesne podejście technologiczne z praktycznym zastosowaniem w edukacji i programowaniu.
Może on służyć jako narzędzie dydaktyczne, ułatwiając naukę teorii kompilacji, w pracach badawczych, a także jako kompleksowe narzędzie do tworzenia praktycznych rozwiązań.


\section{Przegląd istniejących rozwiązań}
\label{sec:przeglad-istniejacych-rozwiazan}

Dostępne na rynku rozwiązania umożliwiają tworzenie analizatorów, jednak charakteryzują się ograniczeniami związanymi z wydajnością, wysokim progiem wejścia i diagnostyką błędów.

\subsection{Lex, Yacc}
\label{sec:lex-yacc}

\textit{Lex}\cite{lesk1975lex} i \textit{Yacc}\cite{johnson1975yacc} to klasyczne, dobrze ugruntowane narzędzia, które odegrały kluczową rolę w tworzeniu setek współczesnych języków programowania.
Definicja leksera i parsera w tych systemach odbywa się poprzez specjalnie zaprojektowaną składnię konfiguracyjną.
Mimo pewnych zalet, jego złożoność i wysoki próg wejścia mogą stanowić wyzwanie.

Ponieważ \textit{Lex} i \textit{Yacc} zostały zaprojektowane do współpracy z językiem C, ich integracja z nowoczesnymi językami programowania bywa utrudniona.
Rozszerzanie tych narzędzi o dodatkowe, specyficzne funkcjonalności jest skomplikowane, co ogranicza ich elastyczność.
Brak wsparcia dla współczesnych środowisk programistycznych (IDE) dodatkowo obniża komfort użytkowania w porównaniu z nowoczesnymi alternatywami.

\begin{lstlisting}[language=c,float=!htbp,caption={Fragment definicji parsera Ruby w technologii Yacc},label={lst:lstlisting2}]
        | command_asgn
    | mlhs '=' command_call
        {
        /*%%%*/
        value_expr($3);
        $1->nd_value = $3;
        $$ = $1;
        /*%
        $$ = dispatch2(massign, $1, $3);
        %*/
        }
    | var_lhs tOP_ASGN command_call
        {
        value_expr($3);
        $$ = new_op_assign($1, $2, $3);
        }
    | primary_value '[' opt_call_args rbracket tOP_ASGN command_call
        {
        /*%%%*/
        NODE *args;

        value_expr($6);
        if (!$3) $3 = NEW_ZARRAY();
        args = arg_concat($3, $6);
        if ($5 == tOROP) {
            $5 = 0;
        }
        else if ($5 == tANDOP) {
            $5 = 1;
        }
        $$ = NEW_OP_ASGN1($1, $5, args);
        fixpos($$, $1);
        /*%
        $$ = dispatch2(aref_field, $1, escape_Qundef($3));
        $$ = dispatch3(opassign, $$, $5, $6);
        %*/
        }
    | primary_value '.' tIDENTIFIER tOP_ASGN command_call
        {
        value_expr($5);
        $$ = new_attr_op_assign($1, ripper_id2sym('.'), $3, $4, $5);
        }
    | primary_value '.' tCONSTANT tOP_ASGN command_call
        {
        value_expr($5);
        $$ = new_attr_op_assign($1, ripper_id2sym('.'), $3, $4, $5);
        }
\end{lstlisting}

\subsection{PLY, SLY}
\label{subsec:ply-sly}

\textit{PLY}\cite{ply} i jego nowszy odpowiednik \textit{SLY}\cite{sly} to biblioteki inspirowane narzędziami Lex i Yacc.
Oferują elastyczne podejście do budowy parserów, umożliwiając samodzielną implementację obsługi leksemów, budowę drzewa AST, czy dodatkowe funkcjonalności takie jak obliczanie numeru linii w lekserze.

Głównym ograniczeniem PLY i SLY jest implementacja w języku Python.
Ze względu na interpretowany charakter oraz dynamiczne typowanie, parsery te charakteryzują się niską wydajnością, a brak statycznego typowania utrudnia wykrywanie błędów na etapie kompilacji.
Przy implementacji parserów z użyciem biblioteki SLY w środowisku PyCharm obserwuje się wiele ostrzeżeń dotyczących potencjalnych naruszeń reguł, co często wymaga zastosowania mechanizmów supresji, aby uniknąć fałszywie pozytywnych wyników analizy statycznej kodu.
Ponadto należy zaznaczyć, iż autor projektu inforuje o braku dalszego rozwoju tych narzędzi\cite{sly-github}.

Przykład ilustruje kilka nieintuicyjnych, automatycznych mechanizmów obecnych w bibliotece \textit{SLY}.
\begin{itemize}
    \item Operator \verb|@_()| jest zdefiniowany, aby automatycznie analizować tekst przy pomocy wyrażeń regularnych.
    Literały muszą być zawarte w cudzysłowie, a „zmienna” odpowiada za matchowany „typ”.
    \item Nazwa metody oznacza „typ” zwracany przez daną produkcję, czyli dla definicji \verb|IF| należy najpierw odszukać wszystkie metody, które mają nazwę \verb|condition|, gdyż są to możliwe produkcje.
    \item W krotce (sic!) \verb|precedence| definiujemy pierwszeństwo operatorów, jednakże dodanie \verb|%| prec pozwala nadpisać priorytet dla konkretnej reguły składniowej.
    \item  Argument \verb|p| pozwala na dostęp do kontekstu produkcji (np. numeru linii), ale także do zmiennych w patternu match w adnotacji.
    Jeśli zdefiniowany jest więcej niż jeden, to dodajemy numer do accesora, np. \verb|expr1| jest odwołaniem się do drugiego wyrażenie \verb|expr|.
    Jednocześnie, można to zrobić także poprzez odwołanie się do konkretnego indeksu obiektu \verb|p|.
\end{itemize}

\begin{lstlisting}[language=Python,float=!htbp,caption={Fragment definicji parsera w Pythonie, wykorzystujacy bibliotekę SLY},label={lst:lstlisting3}]
    class MatrixParser(Parser):
    tokens = MatrixScanner.tokens

    precedence = (
        ('nonassoc', 'IFX'),
        ('nonassoc', 'ELSE'),
        ('nonassoc', 'EQUAL'),
    )

    @_('"{" instructions "}"')
    def block(self, p: YaccProduction):
        raise NotImplementedError

    @_('instruction')
    def block(self, p: YaccProduction):
        raise NotImplementedError

    @_('IF "(" condition ")" block %prec IFX')
    def instruction(self, p: YaccProduction):
        raise NotImplementedError

    @_('IF "(" condition ")" block ELSE block')
    def instruction(self, p: YaccProduction):
        raise NotImplementedError

    @_('expr EQUAL expr')
    def condition(self, p: YaccProduction):
        args = [p.expr0, p.expr1]
        raise NotImplementedError

\end{lstlisting}

Komunikaty błędów w bibliotece \textit{SLY} są bardzo ograniczone.
Na przykład poniższy kod %todo(bkozak: lepsze wprowadzenie kodu)
\begin{lstlisting}[language=Python,float=!htbp,caption={Fragment niedziałajacego kodu w Pythonie, wykorzystujacy bibliotekę SLY},label=lst:maximum]
tokens = Scanner().tokenize("a = 1 + 2")
for tok in tokens:
    print(tok)

\end{lstlisting}

po uruchomieniu informuje użytkownika
\begin{lstlisting}[language=terminal, caption={Przykład komunikatu błędu w bibliotece \textit{SLY}},label={lst:lstlisting}]
  File "main.py", line 2, in <module>
    for tok in tokens:
               ^^^^^^
  File "Python\site-packages\sly\lex.py", line 374, in tokenize
    _set_state(type(self))
    ~~~~~~~~~~^^^^^^^^^^^^
  File "Python\site-packages\sly\lex.py", line 367, in _set_state
    _master_re = cls._master_re
                 ^^^^^^^^^^^^^^
AttributeError: type object 'Scanner' has no attribute '_master_re'
\end{lstlisting}

Okazuje się, że problemem był brak atrybutu \verb|ignore_comment| w definicji Lexera.

\subsection{ANTLR}
\label{subsec:antlr}
%todo(tosz): a gdzie jakaś bibliografia do tego?

\textit{ANTLR} to kolejne rozwiązanie inspirowane narzędziami \textit{Lex} i \textit{Yacc}, oferujące zaawansowane mechanizmy analizy składniowej.
Jego twórcy opracowali dedykowany język DSL, znany jako Grammar v4, który umożliwia definiowanie składni analizowanego języka.
Na podstawie tej definicji \textit{ANTLR} generuje parser w wybranym przez użytkownika języku programowania, takim jak Python, Java, C++ lub JavaScript.

Wspomaganie pracy z \textit{ANTLR} w znacznym stopniu ułatwiają dedykowane wtyczki do środowisk Visual Studio Code oraz IntelliJ IDEA. Oferują one funkcjonalności, takie jak kolorowanie składni, autouzupełnianie kodu, nawigację do definicji leksemów oraz walidację błędów, co znacząco przyspiesza proces tworzenia parserów.

Jedną z kluczowych różnic \textit{ANTLR} w porównaniu do innych narzędzi jest wykorzystanie gramatyki LL(*), podczas gdy klasyczne rozwiązania, takie jak Yacc czy SLY, implementują LALR(1).
LL(*) jest bardziej intuicyjna i czytelna dla programistów, co ułatwia definiowanie reguł składniowych.
Jednakże, jej zastosowanie wiąże się z większym zużyciem pamięci oraz niższą wydajnością w porównaniu do LALR(1).

Dodatkowym wyzwaniem podczas korzystania z \textit{ANTLR} jest konieczność nauki składni DSL Grammar v4 oraz ograniczenie wsparcia dla narzędzi deweloperskich.
Pełne wykorzystanie możliwości \textit{ANTLR} wymaga korzystania z jednego z dedykowanych środowisk, co może stanowić istotne ograniczenie dla użytkowników preferujących inne IDE\@.

\subsection{Alternatywne rozwiązania w języku Scala}
\label{subsec:rozwiazania-w-jezyku-scal}

\subsubsection{Scala parser combinators}
\label{subsubsec:scala-parser-combinators}

Biblioteka \textit{Scala parser combinators}s\cite{moors2008parser} była popularnym sposobem na tworzenie parserów, lecz jak wynika z dokumentacji, „Trudno jest jednak zrozumieć ich działanie i jak zacząć. Po skompilowaniu i uruchomieniu kilku pierwszych przykładów, mechanizm działania staje się bardziej zrozumiały. Ale do tego czasu może to być zniechęcające, a standardowa dokumentacja nie jest zbyt pomocna”\cite{parser-combinators-readme}.

\subsubsection{ScalaBison}
\label{subsubsec:scala-bison}

Z podsumowania artykułu na temat \textit{ScalaBison}\cite{boyland2010tool} wiadomo, że to praktyczny generator parserów dla języka Scala oparty na technologii rekurencyjnego wstępowania i zstępowania, który akceptuje pliki wejściowe w formacie \textit{bison}. Parsery generowane przez \textit{ScalaBison} używają bardziej informacyjnych komunikatów o błędach niż te generowane przez pierwowzór \textit{bison}, a także szybkość parsowania i wykorzystanie miejsca są znacznie lepsze niż \textit{scala-combinators}, ale są nieco wolniejsze niż najszybsze generatory parserów oparte na JVM.

Dodatkowo należy zaznaczyć, iż jest to rozwiązanie już niewspierane i stworzone w celach akademickich.
Korzysta z przestarzałej wersji Scali, nie posiada wyczerpującej dokumentacji i liczba funkcjonalności jest bardzo ograniczona w porównaniu do np. technologii \textit{SLY}.

\subsubsection{parboilded2}
\label{subsubsec:parboiled-2}

\textit{parboiled2}\cite{myltsev2019parboiled2} to biblioteka w Scali umożliwiająca lekkie i szybkie parsowanie dowolnego tekstu wejściowego.
Implementuje ona oparty na makrach generator parsera dla gramatyk wyrażeń parsujących (PEG), który działa w czasie kompilacji i tłumaczy definicję reguły gramatycznej na odpowiadający jej bytecode JVM. Niestety próg wejścia ze względu na skomplikowany i nieintuicyjny DSL jest wysoki.
Zgodnie z przykładem poniżej, raportowanie błędów jest bardzo ograniczone (problem z implementacją wynika jedynie z różnic w liczbie parametrów funkcji).
%todo(bkozak): lepsze linkowanie

\begin{lstlisting}[language=terminal, caption={
    Fragment (sic!) błędu wygenerowanego przez bibliotekę \textit{parboiled2}, który pochodzi z prezentacji Li Haoyi na temat \textit{FastParse}\cite{fastparse-talk}.
},label={lst:lstlisting4}]
    [error] /Users/haoyi/Dropbox (Personal)/(...)/Parser.scala:16: type mismatch;
    [error] found : shapeless.::[Int,shapeless.::[scalatex.stages.Ast.Block,shapeless.HNil]]
    required: scalatex.stages.Ast.Block new Parser(input, offset).Body.run().get
    [error]
    [error] /Users/haoyi/Dropbox (Personal)/(...)/Parser.scala:60: overloaded
    method value apply with alternatives:
    [error] [I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z, RR](f: (I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z, scalatex.stages.Ast. Block.
    Text, scalatex.stages.Ast.Chain, Int, scalatex.stages.Ast.Block) => RR)(implicit j: org.parboiled2.support.ActionOps.SJoin[shapeless.::[!, shapeless.::[J,shapeless.::[K,shapeless.::[L,shapeless.::[M,shapeless.:: [N,shapeless.::[O,shapeless.::[P,shapeless.::[Q,shapeless.::[R, shapeless.::[S,shapeless.::[T,shapeless.::[U,shapeless.::[V,shapeless.:: [W,shapeless.::[X,shapeless.::[Y,shapeless.::[Z,shapeless.
    Ni/////], shapeless.HNil,RR], implicit c: org.parboiled2.support.FCapture[(I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z, scalatex. stages.Ast.Block.Text, scalatex.stages.Ast.Chain, Int, scalatex.stages.Ast.Block) => RR])org.parboiled2.Rule[j.In,j.Out] <and>
    [error] [J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z, RR](f: (J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z, scalatex.stages.Ast.Block. Text, scalatex.stages.Ast.Chain, Int, scalatex.stages.Ast.Block) => RR)(implicit j: org.parboiled2.support.ActionOps.SJoin[shapeless.::[J, shapeless.::[K,shapeless.::[L,shapeless.::[M,shapeless.::[N,shapeless.:: [O,shapeless.::[P,shapeless.::[Q,shapeless.::[R,shapeless.::[S, shapeless.::[T,shapeless.::[U,shapeless.::[V,shapeless.:: [W,shapeless.::[X,shapeless
\end{lstlisting}

\subsubsection{FastParse}
\label{subsubsec:fastparse}

FastParse\textit{FastParse}\cite{fastparse-docs}, opracowana przez Li Haoyi, to wysokowydajna biblioteka kombinatorów parserów dla Scali, zaprojektowana w celu uproszczenia tworzenia parserów tekstu strukturalnego.
Umożliwia ona programistom definiowanie parserów rekurencyjnych, dzięki czemu nadaje się do parsowania języków programowania, formatów danych, takich jak JSON, czy DSL-i.
Cechą charakterystyczną FastParse jest równowaga między użytecznością a wydajnością.
Parsery są konstruowane poprzez łączenie mniejszych parserów za pomocą operatorów, takich jak \verb&~& dla sekwencjonowania i \verb&\|& dla alternatyw, przy jednoczesnym zachowaniu czytelności zbliżonej do formalnych definicji gramatyki.
Według dokumentacji\cite{fastparse-docs}, parsery \textit{Fastparse} zajmują 1/10 kodu w porównaniu do ręcznie napisanego parsera rekurencyjnego.
W porównaniu do narzędzi generujących parsery, takich jak \textit{ANTLR} lub \textit{Lex} i \textit{Yacc}, implementacja nie wymaga żadnego specjalnego kroku kompilacji lub generowania kodu. To sprawia, że rozpoczęcie pracy z \textit{Fastparse} jest znacznie łatwiejsze niż w przypadku bardziej tradycyjnych narzędzi do generowania parserów. Przykładowo, parser wyrażeń arytmetycznych może być zwięźle napisany, aby obsługiwać zagnieżdżone nawiasy, pierwszeństwo operatorów i raportowanie błędów w mniej niż 20 liniach kodu\cite{fastparse-slides}. Biblioteka kładzie również nacisk na debugowanie, generując szczegółowe komunikaty o błędach, które wskazują dokładną lokalizację i przyczynę niepowodzeń parsowania, takich jak niedopasowane nawiasy lub nieprawidłowe tokeny.

\subsection{Podsumowanie}
\label{subsec:podsumowanie}

\newcolumntype{C}{>{\centering\arraybackslash}m{0.15\linewidth}}
\newcolumntype{L}{>{\centering\arraybackslash}m{0.15\linewidth}}
\begin{table}[ht]
    \centering
    \begin{tabular}{L|CCCC}
        \toprule
        \large{Narzędzie}       & \textbf{Lex\&Yacc}                        & \textbf{PLY/SLY}     & \textbf{ANTLR}     & \textbf{scala-bison} \\
        \midrule
        Język implementacji     & C                                         & Python               & Java               & Scala (nad Bisonem)  \\
        \arrayrulecolor{gray}
        \hline
        Język użycia            & regex, BNF, akcje w C                     & DSL                  & DSL oparty na EBNF & BNF, akcje w Scali   \\
        \hline
        Wydajność               & wysoka                                    & niska                & umiarkowana        & wysoka               \\
        \hline
        Łatwość użycia          & średnia                                   & umiarkowana          & wysoka             & średnia              \\
        \hline
        Aktywne wsparcie        & brak                                      & nie                  & tak                & nie                  \\
        \hline
        Diagnostyka błędów      & słaba                                     & średnia              & dobra              & słaba                \\
        \hline
        Dokumentacja            & dobra                                     & średnia, nieaktualna & dobra              & słaba                \\
        \hline
        Popularność             & wysoka                                    & średnia              & wysoka             & niska                \\
        \hline
        Integracja IDE          & nieoficjalny plugin                       & ograniczona          & oficjalny plugin   & brak                 \\
        \hline
        Wsparcie do debugowania & brak                                      & dobre                & częściowe          & dobre                \\
        \hline
        Generowania kodu        & nie                                       & nie                  & tak                & nie                  \\
        \hline
        \toprule
        Narzędzie               & \textbf{Scala parser\newline combinators} & \textbf{parboiled2}  & \textbf{FastParse} & \textbf{ALPACA} \\
        \midrule
        Język implementacji     & Scala                                     & Scala                & Scala              & Scala                \\
        \hline
        Język użycia            & DSL w Scali                               & DSL w Scali          & DSL w Scali        & Scala                \\
        \hline
        Wydajność               & wysoka                                    & umiarkowana          & wysoka             & TODO                 \\
        \hline
        Łatwość użycia          & niska                                     & średnia              & średnia            & TODO                 \\
        \hline
        Aktywne wsparcie        & nie                                       & nie                  & tak                & TODO                 \\
        \hline
        Diagnostyka błędów      & dobra                                     & niska                & dobra              & TODO                 \\
        \hline
        Dokumentacja            & słaba                                     & bardzo dobra         & bardzo dobra       & TODO                 \\
        \hline
        Popularność             & średnia                                   & niska                & rosnąca            & TODO                 \\
        \hline
        Integracja IDE          & wsparcie dla Scali                        & wsparcie dla Scali   & wsparcie dla Scali & TODO                 \\
        \hline
        Wsparcie do debugowania & dobre                                     & dobre                & dobre              & TODO                 \\
        \hline
        Generowania kodu        & nie                                       & nie                  & nie                & TODO                 \\
        \bottomrule
    \end{tabular}
    \caption{Porównanie wybranych narzędzi do generowania lekserów i parserów}
    \label{tab:porownanie-alternatyw}
\end{table}
