\chapter{Cel prac i wizja projektu}
\label{ch:cel-wizja}


\section{Charakterystyka problemu}
\label{sec:charakterystyka-problemu}
Leksery i parsery są kluczowymi elementami w procesie tworzenia interpreterów i kompilatorów języków programowania.
Pozwalają one przekształcić kod źródłowy napisany przez programistę na reprezentację wewnętrzną, wykorzystywaną później przez dalsze etapy przetwarzania kodu.

Analiza leksykalna wykonywana przez lekser polega na rozdzieleniu kodu źródłowego na jednostki logiczne, zwane leksemami.
Parser natomiast wykonuje analizę składniową w celu ustalenia struktury gramatycznej tekstu i jej zgodności z gramatyką języka.

Celem pracy inżynierskiej jest stworzenie narzędzia \textit{ALPACA} (Another Lexer Parser And Compiler Alpaca) w języku Scala, które implementuje funkcjonalności powszechnie stosowane w budowie lekserów i parserów.


\section{Motywacja projektu}
\label{sec:motywacja-projektu}

Projekt ma na celu stworzenie nowoczesnego narzędzia do generowania lekserów i parserów w języku Scala, łączącego zalety istniejących rozwiązań z nowoczesnym podejściem technologicznym.
Jego główne cele to:
\begin{enumerate}
    \item Stworzenie intuicyjnego API\@.
    \item Opracowanie obszernej dokumentacji.
    \item Rozbudowana diagnostyka błędów.
    \item Poprawa wydajności względem rozwiązań w języku Python.
    \item Integracja z popularnymi środowiskami programistycznymi (IDE).
\end{enumerate}

Proponowane rozwiązanie łączy nowoczesne podejście technologiczne z praktycznym zastosowaniem w edukacji i programowaniu.
Może on służyć jako narzędzie dydaktyczne, ułatwiając naukę teorii kompilacji, w pracach badawczych, a także jako kompleksowe narzędzie do tworzenia praktycznych rozwiązań.


\section{Przegląd istniejących rozwiązań}
\label{sec:przeglad-istniejacych-rozwiazan}

Dostępne na rynku rozwiązania umożliwiają tworzenie analizatorów, jednak charakteryzują się ograniczeniami związanymi z wydajnością, wysokim progiem wejścia i diagnostyką błędów.

\subsection{Lex, Yacc}
\label{subsec:lex-yacc}

\textit{Lex}\cite{lesk1975lex} i \textit{Yacc}\cite{johnson1975yacc} to klasyczne, dobrze ugruntowane narzędzia, które odegrały kluczową rolę w tworzeniu setek współczesnych języków programowania.
Definicja leksera i parsera w tych systemach odbywa się poprzez specjalnie zaprojektowaną składnię konfiguracyjną.
Mimo pewnych zalet, jego złożoność i wysoki próg wejścia mogą stanowić wyzwanie.

Ponieważ \textit{Lex} i \textit{Yacc} zostały zaprojektowane do współpracy z językiem C, ich integracja z nowoczesnymi językami programowania bywa utrudniona.
Rozszerzanie tych narzędzi o dodatkowe, specyficzne funkcjonalności jest skomplikowane, co ogranicza ich elastyczność.
Brak wsparcia dla współczesnych środowisk programistycznych (IDE) dodatkowo obniża komfort użytkowania w porównaniu z nowoczesnymi alternatywami.
\lstinputlisting[language=c,caption={Fragment definicji parsera Ruby w technologii Yacc},label={lst:ruby-parser}]{listings/chapter1/parse.y}

\subsection{PLY, SLY}
\label{subsec:ply-sly}

\textit{PLY}\cite{ply} i jego nowszy odpowiednik \textit{SLY}\cite{sly} to biblioteki inspirowane narzędziami Lex i Yacc.
Oferują elastyczne podejście do budowy parserów, umożliwiając samodzielną implementację obsługi leksemów, budowę drzewa AST, czy dodatkowe funkcjonalności takie jak obliczanie numeru linii w lekserze.

Głównym ograniczeniem PLY i SLY jest implementacja w języku Python.
Ze względu na interpretowany charakter oraz dynamiczne typowanie, parsery te charakteryzują się niską wydajnością, a brak statycznego typowania utrudnia wykrywanie błędów na etapie kompilacji.
Przy implementacji parserów z użyciem biblioteki SLY w środowisku PyCharm obserwuje się wiele ostrzeżeń dotyczących potencjalnych naruszeń reguł, co często wymaga zastosowania mechanizmów supresji, aby uniknąć fałszywie pozytywnych wyników analizy statycznej kodu.
Ponadto należy zaznaczyć, iż autor projektu informuje o braku dalszego rozwoju tych narzędzi\cite{sly-github}.

Przykład \ref{lst:python-parser} ilustruje kilka nieintuicyjnych, automatycznych mechanizmów obecnych w bibliotece \textit{SLY}.
\begin{itemize}
    \item Operator \verb|@_()| jest zdefiniowany, aby automatycznie analizować tekst przy pomocy wyrażeń regularnych.
    Literały muszą być zawarte w cudzysłowie, a „zmienna” odpowiada za matchowany „typ”.
    \item Nazwa metody oznacza „typ” zwracany przez daną produkcję, czyli dla definicji \verb|IF| należy najpierw odszukać wszystkie metody, które mają nazwę \verb|condition|, gdyż są to możliwe produkcje.
    \item W krotce (sic!) \verb|precedence| definiujemy pierwszeństwo operatorów, jednakże dodanie \verb|% prec| pozwala nadpisać priorytet dla konkretnej reguły składniowej.
    \item  Argument \verb|p| pozwala na dostęp do kontekstu produkcji (np. numeru linii), ale także do zmiennych w patternu match w adnotacji.
    Jeśli zdefiniowany jest więcej niż jeden, to dodajemy numer do accesora, np. \verb|expr1| jest odwołaniem się do drugiego wyrażenie \verb|expr|.
    Jednocześnie, można to zrobić także poprzez odwołanie się do konkretnego indeksu obiektu \verb|p|.
\end{itemize}

\lstinputlisting[language=Python,caption={Fragment definicji parsera w Pythonie, wykorzystujacy bibliotekę SLY},label={lst:python-parser}]{listings/chapter1/sly-parser.py}

Komunikaty błędów w bibliotece \textit{SLY} są bardzo ograniczone, co obrazuje przykład \ref{lst:not-working-sly}, który po uruchomieniu informuje użytkownika błędem z fragmentu kodu \ref{lst:lstlisting}.
Okazuje się, że problemem był brak atrybutu \verb|ignore_comment| w definicji \verb|Lexer|.
\lstinputlisting[language=Python,caption={Fragment niedziałajacego kodu w Pythonie, wykorzystujacy bibliotekę SLY},label={lst:not-working-sly}]{listings/chapter1/not-working-sly.py}

\lstinputlisting[language=terminal, caption={Przykładowy komunikat błędu w bibliotece \textit{SLY}},label={lst:sly-result}]{listings/chapter1/not-working-result}

\subsection{ANTLR}
\label{subsec:antlr}

\textit{ANTLR}\cite{parr2004s} to kolejne rozwiązanie inspirowane narzędziami \textit{Lex} i \textit{Yacc}, oferujące zaawansowane mechanizmy analizy składniowej.
Jego twórcy opracowali dedykowany język DSL, znany jako Grammar v4, który umożliwia definiowanie składni analizowanego języka.
Na podstawie tej definicji \textit{ANTLR} generuje parser w wybranym przez użytkownika języku programowania, takim jak Python, Java, C++ lub JavaScript.

Wspomaganie pracy z \textit{ANTLR} w znacznym stopniu ułatwiają dedykowane wtyczki do środowisk Visual Studio Code oraz IntelliJ IDEA. Oferują one funkcjonalności, takie jak kolorowanie składni, autouzupełnianie kodu, nawigację do definicji leksemów oraz walidację błędów, co znacząco przyspiesza proces tworzenia parserów.

Jedną z kluczowych różnic \textit{ANTLR} w porównaniu do innych narzędzi jest wykorzystanie gramatyki LL(*), podczas gdy klasyczne rozwiązania, takie jak Yacc czy SLY, implementują LALR(1).
LL(*) jest bardziej intuicyjna i czytelna dla programistów, co ułatwia definiowanie reguł składniowych.
Jednakże, jej zastosowanie wiąże się z większym zużyciem pamięci oraz niższą wydajnością w porównaniu do LALR(1).

Dodatkowym wyzwaniem podczas korzystania z \textit{ANTLR} jest konieczność nauki składni DSL Grammar v4 oraz ograniczenie wsparcia dla narzędzi deweloperskich.
Pełne wykorzystanie możliwości \textit{ANTLR} wymaga korzystania z jednego z dedykowanych środowisk, co może stanowić istotne ograniczenie dla użytkowników preferujących inne IDE\@.

\subsection{Scala parser combinators}
\label{subsec:scala-parser-combinators}

Biblioteka \textit{Scala parser combinators}\cite{moors2008parser} była popularnym sposobem na tworzenie parserów, lecz jak wynika z dokumentacji, „Trudno jest jednak zrozumieć ich działanie i jak zacząć.
Po skompilowaniu i uruchomieniu kilku pierwszych przykładów, mechanizm działania staje się bardziej zrozumiały, ale do tego czasu może to być zniechęcające, a standardowa dokumentacja nie jest zbyt pomocna”\cite{parser-combinators-readme}.

\subsection{ScalaBison}
\label{subsec:scala-bison}

Z podsumowania artykułu na temat \textit{ScalaBison}\cite{boyland2010tool} wiadomo, że to praktyczny generator parserów dla języka Scala oparty na technologii rekurencyjnego wstępowania i zstępowania, który akceptuje pliki wejściowe w formacie \textit{bison}.
Parsery generowane przez \textit{ScalaBison} używają bardziej informacyjnych komunikatów o błędach niż te generowane przez pierwowzór \textit{bison}, a także szybkość parsowania i wykorzystanie miejsca są znacznie lepsze niż \textit{scala-combinators}, ale są nieco wolniejsze niż najszybsze generatory parserów oparte na JVM.

Dodatkowo należy zaznaczyć, iż jest to rozwiązanie już niewspierane i stworzone w celach akademickich.
Korzysta z przestarzałej wersji Scali, nie posiada wyczerpującej dokumentacji i liczba funkcjonalności jest bardzo ograniczona w porównaniu do np. technologii \textit{SLY}.

\subsection{parboiled2}
\label{subsec:parboiled-2}

\textit{parboiled2}\cite{myltsev2019parboiled2} to biblioteka w Scali umożliwiająca lekkie i szybkie parsowanie dowolnego tekstu wejściowego.
Implementuje ona oparty na makrach generator parsera dla gramatyk wyrażeń parsujących (PEG), który działa w czasie kompilacji i tłumaczy definicję reguły gramatycznej na odpowiadający jej bytecode JVM. Niestety próg wejścia ze względu na skomplikowany i nieintuicyjny DSL jest wysoki.
Zgodnie z przykładem \ref{lst:parboiled2-error}, raportowanie błędów jest bardzo ograniczone (problem z implementacją wynika jedynie z różnic w liczbie parametrów funkcji).

\lstinputlisting[firstline=7, lastline=20,language=terminal,caption={[Fragment błędu wygenerowanego przez bibliotekę parboiled2]
Niewielki fragment (14 z 133 linii) błędu wygenerowanego przez bibliotekę \textit{parboiled2}, który pochodzi z prezentacji Li Haoyi na temat \textit{FastParse}\cite{fastparse-talk}.
},label={lst:parboiled2-error}]{listings/chapter1/parboiled2-error}

\subsection{FastParse}
\label{subsec:fastparse}

FastParse\textit{FastParse}\cite{fastparse-docs} to opracowana przez Li Haoyi, wysokowydajna biblioteka kombinatorów parserów dla Scali, zaprojektowana w celu uproszczenia tworzenia parserów tekstu strukturalnego.
Umożliwia ona programistom definiowanie parserów rekurencyjnych, dzięki czemu nadaje się do parsowania języków programowania, formatów danych, takich jak JSON, czy DSL-i.
Cechą charakterystyczną FastParse jest równowaga między użytecznością a wydajnością.
Parsery są konstruowane poprzez łączenie mniejszych parserów za pomocą operatorów, takich jak \verb&~& dla sekwencjonowania i \verb&|& dla alternatyw, przy jednoczesnym zachowaniu czytelności zbliżonej do formalnych definicji gramatyki.
Według dokumentacji\cite{fastparse-docs}, parsery \textit{Fastparse} zajmują 1/10 kodu w porównaniu do ręcznie napisanego parsera rekurencyjnego.
W porównaniu do narzędzi generujących parsery, takich jak \textit{ANTLR} lub \textit{Lex} i \textit{Yacc}, implementacja nie wymaga żadnego specjalnego kroku kompilacji lub generowania kodu.
To sprawia, że rozpoczęcie pracy z \textit{Fastparse} jest znacznie łatwiejsze niż w przypadku bardziej tradycyjnych narzędzi do generowania parserów.
Przykładowo, parser wyrażeń arytmetycznych może być zwięźle napisany, aby obsługiwać zagnieżdżone nawiasy, pierwszeństwo operatorów i raportowanie błędów w mniej niż 20 liniach kodu\cite{fastparse-slides}.
Biblioteka kładzie również nacisk na debugowanie, generując szczegółowe komunikaty o błędach, które wskazują dokładną lokalizację i przyczynę niepowodzeń parsowania, takich jak niedopasowane nawiasy lub nieprawidłowe tokeny.

\subsection{Podsumowanie}
\label{subsec:podsumowanie}

\begin{table}[ht]
    \centering
    \begin{tabular}{L|CCCC}
        \toprule
        \large{Narzędzie}       & \textbf{Lex\&Yacc}                        & \textbf{PLY/SLY}     & \textbf{ANTLR}     & \textbf{scala-bison} \\
        \midrule
        Język implementacji     & C                                         & Python               & Java               & Scala (nad Bisonem)  \\
        \arrayrulecolor{gray}
        \hline
        Język użycia            & regex, BNF, akcje w C                     & DSL                  & DSL oparty na EBNF & BNF, akcje w Scali   \\
        \hline
        Wydajność               & wysoka                                    & niska                & umiarkowana        & wysoka               \\
        \hline
        Łatwość użycia          & średnia                                   & umiarkowana          & wysoka             & średnia              \\
        \hline
        Aktywne wsparcie        & brak                                      & nie                  & tak                & nie                  \\
        \hline
        Diagnostyka błędów      & słaba                                     & średnia              & dobra              & słaba                \\
        \hline
        Dokumentacja            & dobra                                     & średnia, nieaktualna & dobra              & słaba                \\
        \hline
        Popularność             & wysoka                                    & średnia              & wysoka             & niska                \\
        \hline
        Integracja IDE          & nieoficjalny plugin                       & ograniczona          & oficjalny plugin   & brak                 \\
        \hline
        Wsparcie do debugowania & brak                                      & dobre                & częściowe          & dobre                \\
        \hline
        Generowania kodu        & nie                                       & nie                  & tak                & nie                  \\
        \hline
        \toprule
        Narzędzie               & \textbf{Scala parser\newline combinators} & \textbf{parboiled2}  & \textbf{FastParse} & \textbf{ALPACA} \\
        \midrule
        Język implementacji     & Scala                                     & Scala                & Scala              & Scala                \\
        \hline
        Język użycia            & DSL w Scali                               & DSL w Scali          & DSL w Scali        & Scala                \\
        \hline
        Wydajność               & wysoka                                    & umiarkowana          & wysoka             & TODO                 \\
        \hline
        Łatwość użycia          & niska                                     & średnia              & średnia            & TODO                 \\
        \hline
        Aktywne wsparcie        & nie                                       & nie                  & tak                & TODO                 \\
        \hline
        Diagnostyka błędów      & dobra                                     & niska                & dobra              & TODO                 \\
        \hline
        Dokumentacja            & słaba                                     & bardzo dobra         & bardzo dobra       & TODO                 \\
        \hline
        Popularność             & średnia                                   & niska                & rosnąca            & TODO                 \\
        \hline
        Integracja IDE          & wsparcie dla Scali                        & wsparcie dla Scali   & wsparcie dla Scali & TODO                 \\
        \hline
        Wsparcie do debugowania & dobre                                     & dobre                & dobre              & TODO                 \\
        \hline
        Generowania kodu        & nie                                       & nie                  & nie                & TODO                 \\
        \bottomrule
    \end{tabular}
    \caption{Porównanie wybranych narzędzi do generowania lekserów i parserów}
    \label{tab:porownanie-alternatyw}
\end{table}

\subsection{Analiza ryzyka}
\label{subsec:analiza-ryzyka}

Realizacja projektu wiąże się z szeregiem potencjalnych zagrożeń, które mogą wpłynąć na jego przebieg oraz ostateczny rezultat. Poniżej przedstawiono najważniejsze ryzyka zidentyfikowane na etapie planowania, wraz z proponowanymi działaniami minimalizującymi ich wpływ:

\begin{itemize}
    \item \textbf{Złożoność algorytmów parsingu:}
    Implementacja narzędzi takich jak lekser i parser od podstaw stanowi złożone wyzwanie wymagające zaawansowanej wiedzy z zakresu teorii kompilacji oraz algorytmiki. Może to prowadzić do opóźnień lub nawet uniemożliwić realizację projektu. W celu ograniczenia tego ryzyka przeprowadzono pogłębioną analizę zagadnień związanych z gramatykami formalnymi, automatami skończonymi oraz wyrażeniami regularnymi. Wykorzystano również istniejące rozwiązania jako punkt odniesienia w zakresie projektowania architektury systemu.
    
    \item \textbf{Wydajność rozwiązania:}
    Jednym z głównych założeń projektu jest stworzenie narzędzia o wyższej wydajności niż analogiczne rozwiązania dostępne w języku Python. Niespełnienie tego założenia mogłoby znacząco ograniczyć użyteczność biblioteki. W celu zapewnienia wysokiej efektywności obliczeniowej wybrano język Scala, a kluczowe elementy analizatora syntaktycznego realizowane są z wykorzystaniem makr kompilacyjnych, co pozwala na przeniesienie części obliczeń na etap kompilacji i znaczące przyspieszenie działania programu w czasie wykonywania.
    
    \item \textbf{Brak kompatybilności z popularnymi zintegrowanymi środowiskami programistycznymi (IDE):}
    Istniejące narzędzia do generowania analizatorów często nie oferują wsparcia dla współczesnych środowisk IDE, co utrudnia ich użycie i debugowanie. Projekt zakłada implementację biblioteki w czystym języku Scala, bez wykorzystania dedykowanego języka dziedzinowego (DSL), co umożliwia jej integrację z popularnymi narzędziami deweloperskimi wspierającymi Scalę, takimi jak IntelliJ IDEA czy Metals.
    
    \item \textbf{Wysoki próg wejścia:}
    Złożoność i różnorodność istniejących narzędzi do tworzenia parserów skutkuje trudnościami w ich opanowaniu. Projekt przewiduje zaprojektowanie przejrzystego i intuicyjnego interfejsu programistycznego (API) oraz przygotowanie kompleksowej dokumentacji technicznej. Działania te mają na celu obniżenie bariery wejścia i ułatwienie użytkownikom rozpoczęcia pracy z biblioteką.
    
    \item \textbf{Złożoność mechanizmów metaprogramowania w języku Scala:}
    W celu osiągnięcia zakładanej wydajności oraz elastyczności projekt wykorzystuje zaawansowane techniki metaprogramowania dostępne w języku Scala. Ich zastosowanie wymaga pogłębionej znajomości języka oraz jego systemu makr. W celu ograniczenia ryzyka wynikającego z potencjalnych trudności technicznych, przeprowadzono szczegółową analizę dokumentacji języka oraz ukończono specjalistyczny kurs z zakresu metaprogramowania w Scali\cite{scala-course}.
    
    \item \textbf{Zbyt szeroki zakres funkcjonalny projektu:}
    Zakres planowanych funkcjonalności może przekraczać możliwości realizacyjne w ramach dostępnego czasu. Aby ograniczyć to ryzyko, projekt został podzielony na etapy według priorytetu wdrażania funkcji. W przypadku napotkania trudności możliwe będzie zakończenie projektu z działającym minimalnym zakresem funkcjonalnym (MVP), spełniającym podstawowe założenia.
\end{itemize}

