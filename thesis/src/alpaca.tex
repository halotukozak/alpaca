%%%%%% -*- Coding: utf-8-unix; Mode: latex

\documentclass[polish]{aghengthesis}

\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{subfigure}
\usepackage{ragged2e}
\usepackage{multirow}
\usepackage{grffile}
\usepackage{indentfirst}
\usepackage{listings}
\usepackage[ruled,linesnumbered,lined]{algorithm2e}
\usepackage{caption}
\usepackage[bookmarks=false]{hyperref}

\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{array}
\usepackage[table]{xcolor}

\hypersetup{colorlinks,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue}

\usepackage[svgnames]{xcolor}
\usepackage{inconsolata}

\usepackage{csquotes}
\DeclareQuoteStyle[quotes]{polish}
{\quotedblbase}
{\textquotedblright}
[0.05em]
{\quotesinglbase}
{\fixligatures\textquoteright}
\DeclareQuoteAlias[quotes]{polish}{polish}

\usepackage[nottoc]{tocbibind}

\usepackage[
    style=numeric,
    sorting=none,
    isbn=false,
    doi=true,
    url=true,
    backref=false,
    backrefstyle=none,
    maxnames=10,
    giveninits=true,
    abbreviate=true,
    defernumbers=false,
    backend=biber]{biblatex}
\addbibresource{bibliografia.bib}

\lstdefinelanguage{terminal}{
    breaklines=true,
    breakatwhitespace=false,
}

\lstdefinelanguage{Scala}{
    morekeywords={
        abstract,case,catch,class,def,do,else,
        enum,export,extends,false,final,finally,for,
        given,if,implicit,import,lazy,match,new,
        null,object,override,package,private,protected,return,
        sealed,super,then,throw,trait,true,try,
        type,val,var,while,with,yield,
        as,derives,end,extension,infix,inline,opaque,open,transparent,using},
    otherkeywords={<-,=>,<:,>:,@,=>>,?=>,|,*},
    sensitive=true,
    morecomment=[l]{//},
    morecomment=[n]{/*}{*/},
    morecomment=[n]{/**}{*/},
    morestring=[b]",
    morestring=[b]``''"
}[keywords,comments,strings]

\lstdefinelanguage{json}{
    breaklines=true,
    breakatwhitespace=false,
}

\usepackage{fontspec}
\setmonofont{JetBrains Mono}[Contextuals=Alternate]

\lstset{
    basicstyle=\ttfamily\footnotesize,
    backgroundcolor=\color{white},
    commentstyle=\it\color{Green},
    keywordstyle=\color{Red},
    stringstyle=\color{Blue},
    numberstyle=\tiny\color{Black},
    escapeinside=`',
    frame=single,
    tabsize=2,
    rulecolor=\color{black!30},
    title=\lstname,
    breaklines=true,
    breakatwhitespace=true,
    framextopmargin=2pt,
    framexbottommargin=2pt,
    extendedchars=false,
    captionpos=b,
    abovecaptionskip=5pt,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\SetAlgorithmName{\LangAlgorithm}{\LangAlgorithmRef}{\LangListOfAlgorithms}
\newcommand{\listofalgorithmes}{\tocfile{\listalgorithmcfname}{loa}}

\renewcommand{\lstlistingname}{\LangListing}
\renewcommand\lstlistlistingname{\LangListOfListings}

\renewcommand{\lstlistoflistings}{\begingroup
\tocfile{\lstlistlistingname}{lol}
\endgroup}

% Definicje nowych rodzajów kolumn w tabeli
\newcolumntype{C}{>{\centering\arraybackslash}m{0.15\linewidth}}
\newcolumntype{L}{>{\raggedright\arraybackslash}m{0.15\linewidth}}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\newcolumntype{Z}{>{\raggedleft\arraybackslash}X}

\captionsetup{
    font=small,
    labelfont=bf,
    labelsep=period,
    skip=5pt
}
\captionsetup[figure]{position=bottom}
\captionsetup[table]{position=bottom}
\captionsetup[lstlisting]{position=bottom}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{Bartosz Buczek, Bartłomiej Kozak}

\titlePL{Implementacja narzędzi lex i yacc z wykorzystaniem metaprogramowania}
\titleEN{Implementation of lexical analyzer (lex) and parser generator (yacc) tools using metaprogramming techniques}

\fieldofstudy{Informatyka}

%\typeofstudies{Stacjonarne}

\supervisor{dr inż.\ Tomasz Służalec}

\date{\the\year}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

    \maketitle

    \thispagestyle{empty}

    \vspace*{\fill}

    \begin{center}
        \large
        \textit{I do see the beauty in the rules, the invisible code of chaos\\
        hiding behind the menacing face of order.}

        \vspace{0.5cm}

        \normalsize
        --- Elliot Alderson, \textit{Mr. Robot (episode eps2.0\_unm4sk-pt1.tc)}
    \end{center}

    \vspace*{\fill}

    \clearpage
    \thispagestyle{empty}
    \vspace*{\fill}
    \clearpage

    \begin{center}
        {\bfseries Abstrakt}
    \end{center}

    \small
    Analizatory leksykalne i składniowe stanowią fundamentalne komponenty procesu kompilacji, realizując fazy transformacji ciągu znaków wejściowych na strumień tokenów oraz weryfikacji zgodności strukturalnej z gramatykami.
    Istniejące narzędzia do konstruowania tych analizatorów wykazują istotne ograniczenia w zastosowaniu do nowoczesnych języków programowania i zintegrowanych środowisk deweloperskich.
    Tradycyjne generatory kodu takie jak Lex/Yacc i ANTLR wymagają zewnętrznych etapów budowania i znajomości języków domenowych, podczas gdy biblioteki interpretowane jak PLY i SLY cechują się słabą wydajnością i ograniczonym bezpieczeństwem typów.
    Kombinatory parserów oferują elastyczność, ale wprowadzają narzut wykonania zmniejszający wydajność w porównaniu do podejść generacyjnych.
    Niniejsza praca przedstawia bibliotekę ALPACA (Another Lexer Parser And Compiler Alpaca) – narzędzie opracowane w Scali 3, które łączy wydajność generatorów kodu z użytecznością bibliotek poprzez możliwości metaprogramowania w czasie kompilacji dostępne w tym języku.
    Teza badawcza postuluje, że wykorzystanie makr Scali 3, mechanizmu cytatów i wstawek oraz typów rafinowanych umożliwia konstrukcję lekserów i parserów o trzech kluczowych właściwościach.
    Po pierwsze, zapewniają one wydajność parsowania porównywalną z innymi narzędziami.
    Po drugie, oferują interfejs programistyczny niezależny od zewnętrznych języków domenowych i w pełni zintegrowany z systemem typów Scali.
    Po trzecie, dostarczają diagnostykę błędów w czasie kompilacji.
    Metodologia wykorzystuje API refleksji TASTy do programatycznego generowania klas anonimowych implementujących logikę tokenizacji i parsowania w trakcie kompilacji.
    Specyfikacja analizy leksykalnej opiera się na wyrażeniach regularnych, co wykorzystuje powszechnie znany formalizm, ograniczając próg wejścia i wspierając praktyczną adopcję narzędzia.
    Analiza składniowa implementuje algorytmy konstrukcji parserów LR(1) poprzez wykorzystanie automatu ze stosem, którego struktura stanowa jest generowana z użyciem funkcji closure i goto do wyznaczania zbiorów elementów LR(1) oraz przejść między stanami automatu.
    Implementacja rozwiązuje krytyczne ograniczenia JVM poprzez techniki fragmentacji metod, umożliwiając kompilację złożonych gramatyk.
    Akcje semantyczne zachowują bezpieczeństwo typów poprzez transformacje AST i przepisywanie referencji między etapami kompilacji.
    System wspiera także rozwiązywanie konfliktów poprzez relacje precedencji oraz walidację gramatyki w czasie kompilacji.
    Ograniczenia precedencji modelowane są jako graf skierowany weryfikowany pod kątem acykliczności metodą DFS z kolorowaniem węzłów; wykryte cykle raportowane są jako niejednoznaczności specyfikacji.
    Reprezentacja grafowa umożliwia ponadto wnioskowanie o relacjach przechodnich, co pozwala automatycznie rozwiązywać konflikty wynikające z pośrednich zależności precedencji.
    Ocena porównuje bibliotekę ALPACA z alternatywnymi narzędziami w testach wydajnościowych obejmujących parsowanie wyrażeń arytmetycznych oraz plików JSON.
    Wyniki wskazują na konkurencyjną wydajność dla struktur iteracyjnych, jednocześnie identyfikując wrażliwość na obciążenia zdominowane przez tokeny ignorowane.
    W obecnej implementacji białe znaki przetwarzane są analogicznie do tokenów właściwych, co prowadzi do degradacji wydajności w przypadkach patologicznych, takich jak głęboko wcięte struktury JSON z dużą liczbą spacji przy niewielkiej ilości treści semantycznej.
    Ograniczenie to wskazano jako kluczowy kierunek dalszych optymalizacji.
    Całościowo wyniki wspierają tezę, że metaprogramowanie w czasie kompilacji może zapewniać wysoką wydajność przy jednoczesnym zwiększeniu użyteczności i integracji z IDE.
    \vspace{1cm}

    {\bfseries Słowa kluczowe:} metaprogramowanie, Scala 3, makra, analizator leksykalny, parser składniowy, parser LR(1), quote-splice, typy rafinowane, generowanie kodu, TASTy refleksja, bezpieczeństwo typów, optymalizacja kompilacji, integracja IDE, gramatyki bezkontekstowe.

    \newpage

    \begin{center}
        {\bfseries Abstract}
    \end{center}

    \small
    Lexical and syntactic analyzers are fundamental components of the compilation process, implementing phases that transform an input character sequence into a token stream and verify structural conformance to grammars.
    Existing tools for constructing these analyzers exhibit significant limitations when applied to modern programming languages and integrated development environments.
    Traditional code generators like Lex/Yacc and ANTLR require external build steps and knowledge of domain-specific languages, while interpreted libraries such as PLY and SLY suffer from poor performance and limited type safety.
    Parser combinator libraries offer flexibility but introduce runtime overhead that reduces performance compared to generation-based approaches.
    This thesis presents ALPACA (Another Lexer Parser And Compiler Alpaca), a Scala 3 library that combines the performance of code generators with the usability of libraries by leveraging Scala 3’s compile-time metaprogramming capabilities.
    The research thesis posits that using Scala 3 macros, the quote–splice mechanism, and refined types enables the construction of lexers and parsers with three key properties.
    Firstly, parsing performance comparable to other tools.
    Secondly, a developer-facing API independent of external domain-specific languages and fully integrated with Scala’s type system.
    Thirdly, compile-time error diagnostics.
    The methodology uses the TASTy reflection API to programmatically generate anonymous classes implementing tokenization and parsing logic during compilation.
    Lexical specifications are expressed using regular expressions, leveraging a widely adopted formalism to reduce the learning burden and improve practical adoption.
    Syntactic analysis implements LR(1) parser construction algorithms by employing a pushdown automaton whose state structure is generated using the closure and goto functions to compute LR(1) item sets and transitions between automaton states.
    The implementation addresses critical JVM constraints through method fragmentation techniques, enabling compilation of complex grammars.
    Semantic actions preserve type safety through AST transformations and cross-stage reference rewriting.
    The system additionally supports precedence-based conflict resolution and compile-time grammar validation.
    Precedence constraints are modeled as a directed graph validated for acyclicity using depth-first search with node coloring; cycles are reported as specification ambiguities.
    The graph representation further enables transitive inference, allowing automatic resolution of conflicts implied by indirect precedence paths.
    Evaluation compares ALPACA with alternative tools using benchmarks for arithmetic expression parsing and JSON parsing.
    Results indicate competitive performance on iterative inputs, while identifying a performance sensitivity in workloads dominated by ignored tokens.
    In the current implementation, whitespace is processed equivalently to regular tokens, leading to degradation on pathological cases such as deeply indented JSON with large volumes of whitespace and limited semantic content.
    This limitation is identified as a primary target for future optimization.
    Overall, the results support the thesis claim that compile-time metaprogramming can deliver high performance while improving usability and IDE integration.

    \vspace{1cm}
    {\bfseries Keywords:} metaprogramming, Scala 3, macros, lexical analyzer, LR(1) parser, quote-splice mechanisms, refined types, code generation, TASTy reflection, type safety, compilation optimization, IDE integration, context-free grammars.

    \clearpage

    \tableofcontents

    \include{introduction}

    \include{metaprogramming}

    \include{implementation}

    \include{lexer-algo}

    \include{parser-algo}

    \include{comparison}

    \include{organization}

    \printbibliography[heading=bibintoc]
    \listoffigures
    \listoftables
% \listofalgorithmes
    \lstlistoflistings

\end{document}
